# ============================================================================
# Standard Library Imports
# ============================================================================
import os
import re
import glob
import time
import hashlib
import bcrypt
import threading
import itertools
from datetime import datetime, timedelta

# ============================================================================
# Third-party Imports
# ============================================================================
import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from openai import OpenAI  # pip install openai>=1.40
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler


# ============================================================================
# [ì¶”ê°€ë¨] LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ChatGPT & Gemini ì§€ì›)
# Added: OpenAIì™€ Gemini LLM í´ë¼ì´ì–¸íŠ¸ ì§€ì›
# ============================================================================

# OpenAI (ChatGPT) Configuration
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY") or os.getenv("OPENAI_API")
gpt_client = OpenAI(api_key=OPENAI_API_KEY) if OPENAI_API_KEY else None
GPT_MODEL = os.getenv("OPENAI_MODEL", "gpt-4.1-mini")

# Gemini Configuration
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
gemini_client = None
GEMINI_MODEL = "gemini-2.0-flash-exp"

# í˜ì´ì§€ ì„¤ì • (ì•± ì „ì²´ì—ì„œ ë‹¨ 1ë²ˆë§Œ!)
st.set_page_config(page_title="ê³µì¡°ê¸° ë°ì´í„° ì²˜ë¦¬", layout="wide")
 
# app2.py (ìƒë‹¨)
try:
    # íŒ¨í‚¤ì§€ë¡œ ì‹¤í–‰ë  ë•Œ
    from .common import (ì ˆê¸°_ë¶„ë¥˜, ahu_replace_once, í•­ëª©ëª…_í•œê¸€,
                          ëƒ‰ìˆ˜ìµœëŒ€ì—´ëŸ‰, ì¦ê¸°ìµœëŒ€ì—´ëŸ‰, PC_CCV_ì—´ëŸ‰, DH_HCV_ì—´ëŸ‰, í•­ëª©_ì—´ëŸ‰ë§µí•‘,
                          get_ìµœëŒ€ì—´ëŸ‰, ë‹¨ê°€_ë”•ì…”ë„ˆë¦¬, get_ë‹¨ê°€, get_motor_device_kwh,
                          ê±´ì‹ì œìŠµí˜•_ê³µì¡°ê¸°, ëƒ‰ê°ì œìŠµí˜•_ê³µì¡°ê¸°)
    from .loader import (HISTORY_DIR, update_history_results, load_final_results, load_detail_results, scan_and_update, load_oa_results, load_oa_daily, load_ahu_detail, get_items_from_final)
    from .viz import (draw_season_year_line, draw_overlay_by_shifted_datetime,
                      show_ê³µì¡°ê¸°ë³„_ì´ë¹„ìš©_ìš”ì•½, show_í•­ëª©ë³„_ì†Œëª¨ë¹„ìš©, add_band, í‰ê· ì„ ì¶”ê°€,
                      BAND_RANGES_RAT, BAND_RANGES_RAH)
except ImportError:
    # íŒŒì¼ë¡œ ì§ì ‘ ì‹¤í–‰ë  ë•Œ
    from common import (ì ˆê¸°_ë¶„ë¥˜, ahu_replace_once, í•­ëª©ëª…_í•œê¸€,
                        ëƒ‰ìˆ˜ìµœëŒ€ì—´ëŸ‰, ì¦ê¸°ìµœëŒ€ì—´ëŸ‰, PC_CCV_ì—´ëŸ‰, DH_HCV_ì—´ëŸ‰, í•­ëª©_ì—´ëŸ‰ë§µí•‘,
                        get_ìµœëŒ€ì—´ëŸ‰, ë‹¨ê°€_ë”•ì…”ë„ˆë¦¬, get_ë‹¨ê°€, get_motor_device_kwh,
                        ê±´ì‹ì œìŠµí˜•_ê³µì¡°ê¸°, ëƒ‰ê°ì œìŠµí˜•_ê³µì¡°ê¸°)
    from loader import (HISTORY_DIR, update_history_results, load_final_results, load_detail_results, scan_and_update, load_oa_results, load_oa_daily, load_ahu_detail, get_items_from_final)
    from viz import (draw_season_year_line, draw_overlay_by_shifted_datetime,
                     show_ê³µì¡°ê¸°ë³„_ì´ë¹„ìš©_ìš”ì•½, show_í•­ëª©ë³„_ì†Œëª¨ë¹„ìš©, add_band, í‰ê· ì„ ì¶”ê°€,
                     BAND_RANGES_RAT, BAND_RANGES_RAH)

try:
    from .app2_loader import load_parquet_data, load_final_results_from_dir
except ImportError:
    from app2_loader import load_parquet_data, load_final_results_from_dir

WATCH_DIR = HISTORY_DIR

# ============================================================================
# [ì¶”ê°€ë¨] data_adapter ì„í¬íŠ¸ (Parquet/Database í†µí•© ë°ì´í„° ì ‘ê·¼ ë ˆì´ì–´)
# Added: data_adapter ëª¨ë“ˆì„ í†µí•´ Parquetì™€ Database ëª¨ë“œ ì§€ì›
# ============================================================================
try:
    from .data_adapter import (
        DataAccessMode,
        load_final_results as load_adapted_final_results,
        load_ahu_detail as load_adapted_ahu_detail,
        load_oa_data as load_adapted_oa_data,
        ensure_ahu_query_lib
    )
except ImportError:
    from data_adapter import (
        DataAccessMode,
        load_final_results as load_adapted_final_results,
        load_ahu_detail as load_adapted_ahu_detail,
        load_oa_data as load_adapted_oa_data,
        ensure_ahu_query_lib
    )

# [ìˆ˜ì •ë¨] DB ëª¨ë“œ ë¡œë” ë¼ìš°íŒ… + ahu_query_lib ìë™ ê²½ë¡œ íƒìƒ‰
# Modified: ahu-backend-server ê²½ë¡œ ìë™ ê°ì§€ ë° DB ëª¨ë“œì—ì„œ data_adapter ì‚¬ìš©
def load_ahu_detail_by_mode(ahu_name: str, mode: DataAccessMode) -> pd.DataFrame:
    if mode == DataAccessMode.DATABASE:
        return load_adapted_ahu_detail(ahu_name, mode=mode)
    return load_ahu_detail(ahu_name)

# íŒŒì¼ í•´ì‹œ
def _list_csvs(folder: str):
    return sorted(glob.glob(os.path.join(folder, "*.csv")))

def _files_signature(paths):
    import hashlib
    md5 = hashlib.md5()
    for p in sorted(paths):
        try:
            with open(p, "rb") as f:
                data = f.read()
        except FileNotFoundError:
            continue
        md5.update(p.encode("utf-8"))
        md5.update(hashlib.md5(data).digest())
    return md5.hexdigest()

# ì´ë²¤íŠ¸ ê°ì²´ (ìŠ¤ë ˆë“œ-ì„¸ì´í”„)
@st.cache_resource
def get_reload_event():
    return threading.Event()

@st.cache_resource
def start_watcher(path: str, _ev):
    class _Handler(FileSystemEventHandler):
        def on_modified(self, event):
            # ë””ë ‰í† ë¦¬ ì´ë²¤íŠ¸ëŠ” ë¬´ì‹œ, CSV íŒŒì¼ë§Œ ê°ì§€
            if not event.is_directory and event.src_path.endswith(".csv"):
                time.sleep(0.5)  # ì €ì¥ ì¤‘ê°„ì— ì•ˆ ê±¸ë¦¬ê²Œ ë”œë ˆì´
                _ev.set()

    observer = Observer()
    observer.schedule(_Handler(), path, recursive=False)
    observer.start()
    return observer

reload_event = get_reload_event()
_ = start_watcher(WATCH_DIR, reload_event)

# í•´ì‹œ ê¸°ë°˜ ë³´ì¡° ì²´í¬
if "files_sig" not in st.session_state:
    st.session_state["files_sig"] = _files_signature(_list_csvs(WATCH_DIR))
else:
    current_sig = _files_signature(_list_csvs(WATCH_DIR))
    if current_sig != st.session_state["files_sig"]:
        st.session_state["files_sig"] = current_sig
        reload_event.set()

# ğŸ”¥ ë©”ì¸ ë£¨í”„ì—ì„œ ì´ë²¤íŠ¸ í™•ì¸
if reload_event.is_set():
    reload_event.clear()
    new_sig = _files_signature(_list_csvs(WATCH_DIR))
    if new_sig != st.session_state["files_sig"]:
        st.session_state["files_sig"] = new_sig
        st.toast("ğŸ“‚ ìƒˆ CSV ê°ì§€ â†’ ìë™ ìƒˆë¡œê³ ì¹¨", icon="âœ…")
        st.rerun()

# ğŸ“‚ ë°ì´í„° ë¡œë“œ
st.header("ğŸ“‚ ë°ì´í„° ë¡œë“œ")

# --- ë°ì´í„° ë¡œë”© ë¡œì§ ê°œì„  ---
progress_bar = st.progress(0, text="íŒŒì¼ ë¶„ì„ ì¤€ë¹„ ì¤‘...")
def update_progress(current, total, file_name):
    progress_bar.progress(current / total, text=f"ğŸ“‚ íŒŒì¼ ë¶„ì„ ì¤‘... ({current}/{total}) - {file_name}")

# ============================================================================
# [ìˆ˜ì •ë¨] ë°ì´í„° ì†ŒìŠ¤ ì„ íƒ (Parquet/Database ëª¨ë“œ ì§ì ‘ ì„ íƒ)
# Original: Parquet íŒŒì¼ë§Œ ì§ì ‘ ë¡œë“œ
# Modified: ì‚¬ìš©ìê°€ Parquet ë˜ëŠ” Database ëª¨ë“œë¥¼ ì§ì ‘ ì„ íƒ
# ============================================================================

# First-time mode selection (shown before data loading)
if "data_source_mode" not in st.session_state:
    st.markdown("---")
    st.markdown("### ğŸ¯ ë°ì´í„° ì†ŒìŠ¤ ì„ íƒ")
    st.markdown("ë¶„ì„í•  ë°ì´í„° ì†ŒìŠ¤ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")

    # Modern card-style selection
    col1, col2 = st.columns(2)

    with col1:
        st.markdown("""
        <div style="padding: 20px; border-radius: 10px; background-color: #f0f2f6; border: 2px solid #cbd5e0;">
            <h3 style="color: #2d3748; margin-bottom: 10px;">ğŸ“ Parquet Files</h3>
            <p style="color: #718096; font-size: 14px; margin-bottom: 15px;">
                ë¡œì»¬ Parquet íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œ
            </p>
        </div>
        """, unsafe_allow_html=True)
        if st.button("Parquet ëª¨ë“œ ì„ íƒ", key="select_parquet", use_container_width=True, type="secondary"):
            st.session_state["data_source_mode"] = "parquet"
            st.rerun()

    with col2:
        st.markdown("""
        <div style="padding: 20px; border-radius: 10px; background-color: #ebf8ff; border: 2px solid #4299e1;">
            <h3 style="color: #2c5282; margin-bottom: 10px;">ğŸ—„ï¸ Database</h3>
            <p style="color: #4a5568; font-size: 14px; margin-bottom: 15px;">
                PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì‹¤ì‹œê°„ ë°ì´í„° ë¡œë“œ
            </p>
        </div>
        """, unsafe_allow_html=True)

        # Check if ahu_query_lib is available
        db_available = ensure_ahu_query_lib() is not None

        if st.button("Database ëª¨ë“œ ì„ íƒ", key="select_database", use_container_width=True, type="primary" if db_available else "secondary"):
            if db_available:
                st.session_state["data_source_mode"] = "database"
                st.rerun()
            else:
                st.error("âŒ ahu_query_libê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                st.code("export PYTHONPATH=/path/to/ahu-backend-server:$PYTHONPATH", language="bash")

    st.markdown("---")
    st.stop()

# Load data based on selected mode
selected_mode = st.session_state.get("data_source_mode", "parquet")

if selected_mode == "parquet":
    should_update = "ë°ì´í„°ë¡œë“œì™„ë£Œ" not in st.session_state or reload_event.is_set()
    with st.spinner("ğŸ“‚ CSV â†’ parquet ì—…ë°ì´íŠ¸ ì¤‘..." if should_update else "ğŸ“‚ Parquet ë°ì´í„° ë¡œë“œ ì¤‘..."):
        df_final_all, df_oa_daily, df_oa_all, did_update = load_parquet_data(
            should_update=should_update,
            update_fn=lambda: update_history_results(progress_callback=update_progress),
            final_fn=load_final_results,
            oa_daily_fn=load_oa_daily,
            oa_all_fn=load_oa_results,
        )

    if did_update:
        st.session_state["ë°ì´í„°ë¡œë“œì™„ë£Œ"] = True
        progress_bar.empty()
        st.success(f"âœ… ì§‘ê³„ ë°ì´í„° {len(df_final_all)}ê±´, OA(ì¼í‰ê· ) {len(df_oa_daily)}ê±´, OA(ê³ í•´ìƒë„) {len(df_oa_all)}ê±´ ë¡œë“œ ì™„ë£Œ")
    else:
        st.success("âœ… ê¸°ì¡´ ë°ì´í„° ì‚¬ìš©")

    st.session_state["initial_data_loaded"] = True
    st.session_state["data_source_used"] = "parquet"
else:
    if "initial_data_loaded" not in st.session_state or st.session_state.get("data_source_used") != "database":
        with st.spinner("ğŸ”„ DATABASE ëª¨ë“œë¡œ ë°ì´í„° ë¡œë“œ ì¤‘..."):
            try:
                # Load from Database
                df_final_all = load_adapted_final_results(mode=DataAccessMode.DATABASE)
                df_oa_daily = load_adapted_oa_data(mode=DataAccessMode.DATABASE, daily=True)
                df_oa_all = load_adapted_oa_data(mode=DataAccessMode.DATABASE, daily=False)

                # [ìˆ˜ì •ë¨] None ë°˜í™˜ ëŒ€ë¹„ (ahu_query_libì—ì„œ None ë¦¬í„´ ì‹œ ì˜¤ë¥˜ ë°©ì§€)
                # Modified: None -> empty DataFrame ë³€í™˜
                if df_final_all is None:
                    df_final_all = pd.DataFrame()
                if df_oa_daily is None:
                    df_oa_daily = pd.DataFrame()
                if df_oa_all is None:
                    df_oa_all = pd.DataFrame()

                st.session_state["initial_data_loaded"] = True
                st.session_state["data_source_used"] = "database"
                st.success("âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ (DATABASE ëª¨ë“œ)")

            except Exception as e:
                st.error(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
                import traceback
                st.error(traceback.format_exc())
                st.info("ğŸ’¡ ë‹¤ë¥¸ ëª¨ë“œë¥¼ ì„ íƒí•˜ë ¤ë©´ ì„¸ì…˜ì„ ë‹¤ì‹œ ì‹œì‘í•˜ì„¸ìš”.")
                st.stop()
    else:
        st.success("âœ… ì„¸ì…˜ ë°ì´í„° ì‚¬ìš© (DATABASE ëª¨ë“œ)")
        df_final_all = load_adapted_final_results(mode=DataAccessMode.DATABASE)
        df_oa_daily = load_adapted_oa_data(mode=DataAccessMode.DATABASE, daily=True)
        df_oa_all = load_adapted_oa_data(mode=DataAccessMode.DATABASE, daily=False)

if selected_mode == "parquet" and (df_final_all is None or df_final_all.empty):
    st.error("ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. history ê²½ë¡œ/ë‚ ì§œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()

if selected_mode == "parquet":
    FINAL_DIR = os.getenv("AHU_FINAL_DIR", r"C:\Users\User\Desktop\ahu_app_results\final_results")
    override_df = load_final_results_from_dir(FINAL_DIR)
    if not override_df.empty:
        df_final_all = override_df
    
#====================================================================================
# ë¡œê·¸ì¸ ê¸°ëŠ¥, ìë™ rerun ê¸°ëŠ¥ ë“± ê¸°íƒ€ ì½”ë“œ... (ì´ ë¶€ë¶„ì€ ë³€ê²½í•˜ì§€ ì•ŠìŒ)
#====================================================================================

st.title("ğŸ“Š ê³µì¡°ê¸° ë¶„ì„ ì‹œìŠ¤í…œ")

# ============================================================================
# [ì¶”ê°€ë¨] ë°ì´í„° ì†ŒìŠ¤ ì„ íƒ (Database vs Parquet)
# Added: ì‚¬ì´ë“œë°”ì—ì„œ Parquet/Database ëª¨ë“œ ì„ íƒ ê¸°ëŠ¥
# ============================================================================
st.sidebar.markdown("---")

if st.sidebar.button("ğŸ§¹ Parquet ê°•ì œ ì¬ë¶„ì„", key="force_rebuild_parquet"):
    st.session_state["ë°ì´í„°ë¡œë“œì™„ë£Œ"] = False
    st.session_state["initial_data_loaded"] = False
    reload_event.set()
    with st.spinner("Parquet ê²€ì¦ì„ ìœ„í•´ ë‹¤ì‹œ ìƒì„± ì¤‘..."):
        update_history_results(progress_callback=update_progress)
    st.sidebar.success("âœ… Parquet ì¬ë¶„ì„ ì™„ë£Œ")
    st.experimental_rerun()

# Get current data source from session state
current_data_source = st.session_state.get("data_source_used", "parquet")

# Set default index based on auto-detected source
default_index = 1 if current_data_source == "database" else 0

data_source_mode = st.sidebar.radio(
    "ğŸ—„ï¸ ë°ì´í„° ì†ŒìŠ¤",
    options=["Parquet Files", "Database"],
    index=default_index,
    help=f"í˜„ì¬: {current_data_source.upper()} ëª¨ë“œ (Parquet Files ë˜ëŠ” Database ì„ íƒ)"
)

# Convert to DataAccessMode enum
mode = DataAccessMode.PARQUET if data_source_mode == "Parquet Files" else DataAccessMode.DATABASE

# Display current mode status
if mode == DataAccessMode.DATABASE:
    try:
        aql = ensure_ahu_query_lib()
        if not aql:
            raise ImportError("ahu_query_lib not available")
        if current_data_source == "database":
            st.sidebar.success("âœ… Database mode (auto-detected)")
        else:
            st.sidebar.success("âœ… Database connected")
        st.sidebar.caption(f"ahu_query_lib v{aql.__version__}")
    except ImportError:
        st.sidebar.error("âŒ ahu_query_lib not installed")
        st.sidebar.caption("Run: export PYTHONPATH=/path/to/ahu-backend-server:$PYTHONPATH")
        # Fallback to parquet mode if library not available
        mode = DataAccessMode.PARQUET
else:
    if current_data_source == "parquet":
        st.sidebar.info("ğŸ“ Using Parquet files (auto-detected)")
    else:
        st.sidebar.info("ğŸ“ Using Parquet files")

st.sidebar.markdown("---")

# ============================================================================
# [ìˆ˜ì •ë¨] ë°ì´í„° ì†ŒìŠ¤ì— ë”°ë¥¸ ë°ì´í„° ë¡œë“œ (Parquet/Database ëª¨ë“œ ì§€ì›)
# Modified: data_adapterë¥¼ í†µí•´ ì„ íƒëœ ëª¨ë“œë¡œ ë°ì´í„° ë¡œë“œ
# ============================================================================
# Note: Database modeì˜ ê²½ìš° energy ë°ì´í„°ëŠ” ë¹„ì–´ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤
# (energy_readings í…Œì´ë¸”ì´ ë¹„ì–´ìˆìŒ). Sensor ë°ì´í„°ëŠ” ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤.
if mode == DataAccessMode.DATABASE and st.sidebar.button("ğŸ”„ DBì—ì„œ ë°ì´í„° ë‹¤ì‹œ ë¡œë“œ", key="reload_db_data"):
    with st.spinner("ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë°ì´í„° ë¡œë“œ ì¤‘..."):
        try:
            # Load data using data_adapter
            df_final_all = load_adapted_final_results(mode=mode)
            ì™¸ê¸°df_daily = load_adapted_oa_data(mode=mode, daily=True)
            ì™¸ê¸°df_hourly = load_adapted_oa_data(mode=mode, daily=False)

            all_df = df_final_all.copy()

            # [ìˆ˜ì •ë¨] Empty DataFrame ì²´í¬ ì¶”ê°€
            # Normalize AHU names (only if DataFrame has the column)
            if not all_df.empty and "ê³µì¡°ê¸°" in all_df.columns:
                all_df["ê³µì¡°ê¸°"] = (
                    all_df["ê³µì¡°ê¸°"]
                      .astype(str)
                      .str.replace(r"AHU-?(\d+)(H)?", lambda m: f"AHU{int(m.group(1)):02d}" + (m.group(2) or ""), regex=True)
                )
            if not df_final_all.empty and "ê³µì¡°ê¸°" in df_final_all.columns:
                df_final_all["ê³µì¡°ê¸°"] = (
                    df_final_all["ê³µì¡°ê¸°"]
                      .astype(str)
                      .str.replace(r"AHU-?(\d+)(H)?", lambda m: f"AHU{int(m.group(1)):02d}" + (m.group(2) or ""), regex=True)
                )

            # [ìˆ˜ì •ë¨] None ë°˜í™˜ ëŒ€ë¹„ (ahu_query_libì—ì„œ None ë¦¬í„´ ì‹œ ì˜¤ë¥˜ ë°©ì§€)
            # Modified: None -> empty DataFrame ë³€í™˜
            if df_final_all is None:
                df_final_all = pd.DataFrame()
            if ì™¸ê¸°df_daily is None:
                ì™¸ê¸°df_daily = pd.DataFrame()
            if ì™¸ê¸°df_hourly is None:
                ì™¸ê¸°df_hourly = pd.DataFrame()

            st.success(f"âœ… DB ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df_final_all)}ê±´ (energy), {len(ì™¸ê¸°df_daily)}ê±´ (OA daily), {len(ì™¸ê¸°df_hourly)}ê±´ (OA hourly)")
            st.sidebar.success("âœ… Database data loaded")

            if df_final_all.empty:
                st.warning("âš ï¸ Energy ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. energy_readings í…Œì´ë¸”ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                st.info("ğŸ’¡ Sensor ë°ì´í„° (Detail view)ëŠ” ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤. Energy ë°ì´í„°ëŠ” ETLì´ í•„ìš”í•©ë‹ˆë‹¤.")

        except Exception as e:
            st.error(f"âŒ DB ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            import traceback
            st.error(traceback.format_exc())

# ì—¬ê¸°ì„œë¶€í„°ëŠ” all_dfì™€ ì™¸ê¸°dfë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
all_df = df_final_all.copy()
ì™¸ê¸°df_daily  = df_oa_daily.copy()
ì™¸ê¸°df_hourly = df_oa_all.copy()

# [ìˆ˜ì •ë¨] Database mode can return timestamp/date columns instead of datetime; normalize once here.
def _normalize_datetime_column(df: pd.DataFrame) -> None:
    if df is None or df.empty or "datetime" in df.columns:
        return
    candidate_cols = ["timestamp", "date", "ë‚ ì§œ"]
    for col in candidate_cols:
        if col in df.columns:
            dt = pd.to_datetime(df[col], errors="coerce")
            if getattr(dt.dt, "tz", None) is not None:
                dt = dt.dt.tz_localize(None)
            df["datetime"] = dt
            return

_normalize_datetime_column(all_df)

# all_df = df_final_all.copy() ë°”ë¡œ ì•„ë˜ì— ì¶”ê°€
# "AHU-07", "AHU7", "AHU007", "AHU07H" ë“± ë³€í˜•ì„ ëª¨ë‘ "AHU07" ë˜ëŠ” "AHU07H"ë¡œ ì •ê·œí™”
# [ìˆ˜ì •ë¨] Empty DataFrame ì²´í¬ ì¶”ê°€ (Database modeì—ì„œ energy ë°ì´í„°ê°€ ë¹„ì–´ìˆì„ ê²½ìš° ëŒ€ì‘)
if not all_df.empty and "ê³µì¡°ê¸°" in all_df.columns:
    all_df["ê³µì¡°ê¸°"] = (
        all_df["ê³µì¡°ê¸°"]
          .astype(str)
          .str.replace(r"AHU-?(\d+)(H)?", lambda m: f"AHU{int(m.group(1)):02d}" + (m.group(2) or ""), regex=True)
    )

# ìš”ì•½ ìŠ¤ëƒ…ìƒ·ë„ ë™ì¼ í‚¤ë¡œ ë§ì¶”ê¸° (df_final_allë„ ê°™ì€ ê·œì¹™ìœ¼ë¡œ)
if not df_final_all.empty and "ê³µì¡°ê¸°" in df_final_all.columns:
    df_final_all["ê³µì¡°ê¸°"] = (
        df_final_all["ê³µì¡°ê¸°"]
          .astype(str)
          .str.replace(r"AHU-?(\d+)(H)?", lambda m: f"AHU{int(m.group(1)):02d}" + (m.group(2) or ""), regex=True)
    )


# final_analysis.parquetìœ¼ë¡œë¶€í„° ë°ì´í„° ì¶”ì¶œ
def get_daily_kwh(df: pd.DataFrame, ahu: str, item: str) -> pd.DataFrame:
    """
    parquet ê¸°ë°˜: ê³µì¡°ê¸°ë³„, í•­ëª©ë³„ ì¼ë³„ kWh í•©ì‚°
    """
    tmp = df[(df["ê³µì¡°ê¸°"] == ahu) & (df["í•­ëª©ëª…"] == item)].copy()
    if tmp.empty:
        return pd.DataFrame(columns=["ë‚ ì§œ", "kWh"])

    # ë‚ ì§œ ì»¬ëŸ¼ ìƒì„±
    if "ë‚ ì§œ" in tmp.columns:
        tmp["ë‚ ì§œ"] = pd.to_datetime(tmp["ë‚ ì§œ"])
    else:
        tmp["ë‚ ì§œ"] = pd.to_datetime(tmp["datetime"]).dt.normalize()

    # ì¼ë³„ kWh í•©ì‚°
    out = tmp.groupby("ë‚ ì§œ", as_index=False)["kWh"].sum()

    return out


def make_top_summary(base_df: pd.DataFrame, raw: bool = False) -> pd.DataFrame:
    """
    ê³µì¡°ê¸°ë³„ ì „ë ¥/ëƒ‰ìˆ˜ì½”ì¼/ìŠ¤íŒ€ì½”ì¼/ì´ë¹„ìš© ì§‘ê³„.

    ìš°ì„ ìˆœìœ„:
      - loader.pyì—ì„œ ë§Œë“¤ì–´ ì¤€ í‘œì¤€ ì»¬ëŸ¼ ì‚¬ìš©:
        ëƒ‰ìˆ˜_ë¹„ìš©(ì›), ìŠ¤íŒ€_ë¹„ìš©(ì›), ì „ë ¥_ë¹„ìš©(ì›), ì´í•©_ë¹„ìš©(ì›)
      - ì—†ìœ¼ë©´ ê°œë³„ ì½”ì¼/ëª¨í„° ë¹„ìš© ì»¬ëŸ¼ì„ ì´ìš©í•´ ì¬ê³„ì‚°
      - ì´ë¹„ìš©(ì›)ì€ í•­ìƒ ì „ë ¥ + ëƒ‰ìˆ˜ + ìŠ¤íŒ€ì˜ í•©ìœ¼ë¡œ ë‹¤ì‹œ ê³„ì‚° (ì´í•©_ë¹„ìš©(ì›) ë§¹ì‹  X)
    """
    if base_df is None or base_df.empty:
        return pd.DataFrame(
            columns=["ê³µì¡°ê¸°", "ì´ë¹„ìš©(ì›)", "ì „ë ¥ì‚¬ìš©ëŸ‰(ì›)", "ëƒ‰ìˆ˜ì½”ì¼ë¹„ìš©(ì›)", "ìŠ¤íŒ€ì½”ì¼ë¹„ìš©(ì›)"]
        )

    df = base_df.copy()

    # ìˆ«ìí™”
    for c in df.columns:
        if "ë¹„ìš©(ì›)" in str(c):
            df[c] = pd.to_numeric(df[c], errors="coerce")

    # â”€â”€ ëƒ‰ìˆ˜ ì½”ì¼ ë¹„ìš© â”€â”€
    if "ëƒ‰ìˆ˜_ë¹„ìš©(ì›)" in df.columns:
        df["ëƒ‰ìˆ˜ì½”ì¼ë¹„ìš©(ì›)"] = df["ëƒ‰ìˆ˜_ë¹„ìš©(ì›)"]
    elif "ë¹„ìš©(ì›)_ëƒ‰ìˆ˜" in df.columns:
        df["ëƒ‰ìˆ˜ì½”ì¼ë¹„ìš©(ì›)"] = df["ë¹„ìš©(ì›)_ëƒ‰ìˆ˜"]
    else:
        ëƒ‰ìˆ˜_cols = [c for c in df.columns if c in ["ë¹„ìš©(ì›)_CCV", "ë¹„ìš©(ì›)_PC_CCV", "ë¹„ìš©(ì›)_AC_CCV"]]
        df["ëƒ‰ìˆ˜ì½”ì¼ë¹„ìš©(ì›)"] = df[ëƒ‰ìˆ˜_cols].sum(axis=1, min_count=1) if ëƒ‰ìˆ˜_cols else np.nan

    # â”€â”€ ìŠ¤íŒ€ ì½”ì¼ ë¹„ìš© â”€â”€
    if "ìŠ¤íŒ€_ë¹„ìš©(ì›)" in df.columns:
        df["ìŠ¤íŒ€ì½”ì¼ë¹„ìš©(ì›)"] = df["ìŠ¤íŒ€_ë¹„ìš©(ì›)"]
    elif "ë¹„ìš©(ì›)_ìŠ¤íŒ€" in df.columns:
        df["ìŠ¤íŒ€ì½”ì¼ë¹„ìš©(ì›)"] = df["ë¹„ìš©(ì›)_ìŠ¤íŒ€"]
    else:
        ìŠ¤íŒ€_cols = [c for c in df.columns if c in ["ë¹„ìš©(ì›)_HCV", "ë¹„ìš©(ì›)_DH_HCV", "ë¹„ìš©(ì›)_AC_HCV"]]
        df["ìŠ¤íŒ€ì½”ì¼ë¹„ìš©(ì›)"] = df[ìŠ¤íŒ€_cols].sum(axis=1, min_count=1) if ìŠ¤íŒ€_cols else np.nan

    # â”€â”€ ì „ë ¥ ë¹„ìš© â”€â”€
    if "ì „ë ¥_ë¹„ìš©(ì›)" in df.columns:
        df["ì „ë ¥ì‚¬ìš©ëŸ‰(ì›)"] = df["ì „ë ¥_ë¹„ìš©(ì›)"]
    elif "ë¹„ìš©(ì›)_ì „ë ¥" in df.columns:
        df["ì „ë ¥ì‚¬ìš©ëŸ‰(ì›)"] = df["ë¹„ìš©(ì›)_ì „ë ¥"]
    else:
        # ì½”ì¼/ì´í•©/ì´ë¯¸ ê³„ì‚°ëœ í‘œì¤€ ì»¬ëŸ¼ ì œì™¸í•œ ë‚˜ë¨¸ì§€ ë¹„ìš© â†’ ì „ë ¥ìœ¼ë¡œ ê°„ì£¼
        exclude = {
            "ëƒ‰ìˆ˜ì½”ì¼ë¹„ìš©(ì›)", "ìŠ¤íŒ€ì½”ì¼ë¹„ìš©(ì›)",
            "ëƒ‰ìˆ˜_ë¹„ìš©(ì›)", "ìŠ¤íŒ€_ë¹„ìš©(ì›)",
            "ë¹„ìš©(ì›)_ëƒ‰ìˆ˜", "ë¹„ìš©(ì›)_ìŠ¤íŒ€",
            "ì´í•©_ë¹„ìš©(ì›)", "ì´í•©_ë¹„ìš©"
        }
        # CCV/HCV ê³„ì—´(ì´ë¯¸ ëƒ‰ìˆ˜/ìŠ¤íŒ€ì— í¬í•¨í•´ì•¼ í•˜ëŠ” ê²ƒ)ë„ ì œì™¸
        coil_patterns = ("_CCV", "_PC_CCV", "_AC_CCV", "_HCV", "_DH_HCV", "_AC_HCV")

        power_cols = []
        for c in df.columns:
            if not str(c).endswith("ë¹„ìš©(ì›)"):
                continue
            if c in exclude:
                continue
            if any(pat in c for pat in coil_patterns):
                continue
            power_cols.append(c)

        df["ì „ë ¥ì‚¬ìš©ëŸ‰(ì›)"] = df[power_cols].sum(axis=1, min_count=1) if power_cols else np.nan

    # â”€â”€ ì´ë¹„ìš©: í•­ìƒ ì „ë ¥ + ëƒ‰ìˆ˜ + ìŠ¤íŒ€ë¡œ ì¬ê³„ì‚° â”€â”€
    base_cols = [c for c in ["ì „ë ¥ì‚¬ìš©ëŸ‰(ì›)", "ëƒ‰ìˆ˜ì½”ì¼ë¹„ìš©(ì›)", "ìŠ¤íŒ€ì½”ì¼ë¹„ìš©(ì›)"] if c in df.columns]
    if base_cols:
        df["ì´ë¹„ìš©(ì›)"] = df[base_cols].sum(axis=1, min_count=1)
    else:
        # ìµœí›„ì˜ ë³´ë£¨: ëª¨ë“  ë¹„ìš©(ì›) í•© (ì´í•©/í‘œì¤€ì»¬ëŸ¼ ì œì™¸)
        tmp_cols = [
            c for c in df.columns
            if str(c).endswith("ë¹„ìš©(ì›)")
            and not str(c).startswith("ì´í•©_")
        ]
        df["ì´ë¹„ìš©(ì›)"] = df[tmp_cols].sum(axis=1, min_count=1) if tmp_cols else np.nan

    # â”€â”€ ê³µì¡°ê¸°ë³„ ì§‘ê³„ â”€â”€
    summary = (
        df.groupby("ê³µì¡°ê¸°", as_index=False)[
            ["ì´ë¹„ìš©(ì›)", "ì „ë ¥ì‚¬ìš©ëŸ‰(ì›)", "ëƒ‰ìˆ˜ì½”ì¼ë¹„ìš©(ì›)", "ìŠ¤íŒ€ì½”ì¼ë¹„ìš©(ì›)"]
        ]
        .sum(min_count=1)
    )

    if raw:
        return summary

    # â”€â”€ í‘œì‹œìš© í¬ë§· â”€â”€
    fmt = summary.copy()
    num_cols = [c for c in fmt.columns if c != "ê³µì¡°ê¸°"]
    for c in num_cols:
        fmt[c] = fmt[c].apply(
            lambda x: f"{int(round(x)):,}" if pd.notna(x) else ""
        )
    fmt.index = np.arange(1, len(fmt) + 1)
    fmt.index.name = "No"
    return fmt


# âœ… ì„¸ì…˜ ì—…ë°ì´íŠ¸
st.session_state['uploaded_df'] = all_df

# ============================================================================
# [ìˆ˜ì •ë¨] Empty DataFrame ì²´í¬ ì¶”ê°€ (Database modeì—ì„œ energy ë°ì´í„°ê°€ ë¹„ì–´ìˆì„ ê²½ìš° ëŒ€ì‘)
# Modified: Database modeì—ì„œ energy ë°ì´í„°ê°€ ë¹„ì–´ìˆì„ ê²½ìš° ì²˜ë¦¬ ê±´ë„ˆë›°ê¸°
# ============================================================================
# Energy ë°ì´í„°ê°€ ë¹„ì–´ìˆìœ¼ë©´ ì²˜ë¦¬ ê±´ë„ˆë›°ê¸° (Database mode ETL í•„ìš”)
if all_df.empty or "datetime" not in all_df.columns:
    st.warning("âš ï¸ Energy ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. energy_readings í…Œì´ë¸”ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    st.info("ğŸ’¡ Sensor ë°ì´í„° (Detail view)ëŠ” ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤. Energy ë°ì´í„°ëŠ” ETLì´ í•„ìš”í•©ë‹ˆë‹¤.")
    st.info("ğŸ’¡ ë°ì´í„°ë¥¼ í™•ì¸í•˜ë ¤ë©´ ì•„ë˜ë¡œ ìŠ¤í¬ë¡¤í•˜ì„¸ìš”.")
else:
    # Energy ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì—°ë„/ì ˆê¸° ì»¬ëŸ¼ ì¶”ê°€
    all_df["ì—°ë„"] = all_df["datetime"].dt.year
    all_df["ì ˆê¸°"] = all_df["datetime"].apply(ì ˆê¸°_ë¶„ë¥˜)

    # Energy ë°ì´í„°ê°€ ìˆì„ ë•Œë§Œ ì•„ë˜ ì²˜ë¦¬ ì‹¤í–‰
    ENERGY_DATA_AVAILABLE = True


# 1) ì½”ì¼(ëƒ‰ìˆ˜/ìŠ¤íŒ€) ë³„ì¹­ ì •ì˜: ë‘ ë²ˆì§¸ í‘œì²˜ëŸ¼ AC_/PC_/DH_ê°€ ë¶™ì–´ë„ ê°™ì€ ì½”ì¼ë¡œ ì·¨ê¸‰
COIL_ALIASES = {
    "CCV": ["CCV", "AC_CCV", "PC_CCV"],      # ëƒ‰ìˆ˜ ì½”ì¼
    "HCV": ["HCV", "AC_HCV", "DH_HCV"],      # ìŠ¤íŒ€ ì½”ì¼
}

# 2) ì ‘ë‘/ì ‘ë¯¸ íŒ¨í„´ìœ¼ë¡œ ì»¬ëŸ¼ ì°¾ê¸° ìœ í‹¸
def _find_metric_cols(df, alias_list, metric): 
    # metric: "kWh" ë˜ëŠ” "ë¹„ìš©(ì›)"
    cols = []
    for alias in alias_list:
        # ì ‘ë‘ì‚¬í˜•: kWh_ALIAS, ë¹„ìš©(ì›)_ALIAS
        cols += [c for c in df.columns if c == f"{metric}_{alias}"]
        # ì ‘ë¯¸ì‚¬í˜•: ALIAS_kWh, ALIAS_ë¹„ìš©(ì›)  (ëŒ€ì†Œë¬¸ì kWh ëª¨ë‘ í—ˆìš©)
        if metric == "kWh":
            cols += [c for c in df.columns if c.lower() == f"{alias}_kwh".lower()]
        else:
            cols += [c for c in df.columns if c == f"{alias}_ë¹„ìš©(ì›)"]
    # ì¤‘ë³µ ì œê±° (ìˆì„ ìˆ˜ ìˆìŒ)
    return sorted(list(dict.fromkeys(cols)))

# 3) ì½”ì¼ë³„(kWh/ë¹„ìš©) ì •ê·œí™” ì»¬ëŸ¼ ìƒì„±: ì—¬ëŸ¬ ë³„ì¹­ì„ í•©ì³ì„œ í•˜ë‚˜ë¡œ ë§Œë“¤ê¸°
for coil, aliases in COIL_ALIASES.items():
    kwh_cols  = _find_metric_cols(all_df, aliases, "kWh")
    cost_cols = _find_metric_cols(all_df, aliases, "ë¹„ìš©(ì›)")
    if kwh_cols:
        all_df[kwh_cols] = all_df[kwh_cols].apply(pd.to_numeric, errors="coerce")
        all_df[f"kWh_{coil}"] = all_df[kwh_cols].sum(axis=1, min_count=1)
    if cost_cols:
        all_df[cost_cols] = all_df[cost_cols].apply(pd.to_numeric, errors="coerce")
        all_df[f"ë¹„ìš©(ì›)_{coil}"] = all_df[cost_cols].sum(axis=1, min_count=1)

# 4) ì „ë ¥(ëª¨í„°ë¥˜) ë¹„ìš©: ì½”ì¼/ì´í•©/ì „ë ¥/ëƒ‰ìˆ˜/ìŠ¤íŒ€ì€ ì œì™¸í•˜ê³ , ì ‘ë‘/ì ‘ë¯¸ ë‘˜ ë‹¤ ì¸ì‹
EXCLUDE_TOKENS = set().union(*COIL_ALIASES.values()) | {"ëƒ‰ìˆ˜","ìŠ¤íŒ€","ì´í•©","ì „ë ¥"}

def _is_power_cost(col):
    # ë¹„ìš©(ì›)_ì¥ì¹˜
    if col.startswith("ë¹„ìš©(ì›)_"):
        dev = col.split("_", 1)[1]
        return dev not in EXCLUDE_TOKENS
    # ì¥ì¹˜_ë¹„ìš©(ì›)
    if col.endswith("_ë¹„ìš©(ì›)"):
        dev = col.rsplit("_", 1)[0]
        return dev not in EXCLUDE_TOKENS
    return False

power_cost_cols = [c for c in all_df.columns if _is_power_cost(c)]
calc_power_cost = None
if power_cost_cols:
    all_df[power_cost_cols] = all_df[power_cost_cols].apply(pd.to_numeric, errors="coerce")
    calc_power_cost = all_df[power_cost_cols].sum(axis=1, min_count=1)

# 5) ë¹„ìš© ì†ŒìŠ¤ê°€ ì—†ê±°ë‚˜ ì „ë¶€ NaNì´ë©´ â†’ ì „ê¸° kWh í•© Ã— ì—°ë„ë³„ ë‹¨ê°€ë¡œ ë³´ì • (kWh ì ‘ë‘/ì ‘ë¯¸ + ì†Œë¬¸ì í—ˆìš©)
def _is_power_kwh(col):
    if col.startswith(("kWh_","kwh_")):
        dev = col.split("_", 1)[1]
        return dev not in {"ëƒ‰ìˆ˜","ìŠ¤íŒ€"} and dev not in EXCLUDE_TOKENS
    if col.lower().endswith("_kwh"):
        dev = col.rsplit("_", 1)[0]
        return dev not in {"ëƒ‰ìˆ˜","ìŠ¤íŒ€"} and dev not in EXCLUDE_TOKENS
    return False

if (calc_power_cost is None) or calc_power_cost.isna().all():
    kwh_cols = [c for c in all_df.columns if _is_power_kwh(c)]
    if kwh_cols:
        all_df[kwh_cols] = all_df[kwh_cols].apply(pd.to_numeric, errors="coerce")
        kwh_sum = all_df[kwh_cols].sum(axis=1, min_count=1)
        def _price_by_year(y):
            try:
                return ë‹¨ê°€_ë”•ì…”ë„ˆë¦¬[int(y)]["ì „ë ¥(ì›/kWh)"]
            except Exception:
                return np.nan
        price = all_df["datetime"].dt.year.map(_price_by_year)
        calc_power_cost = kwh_sum * price

# 6) ì „ë ¥_ë¹„ìš©(ì›) ê²°ì¸¡ë§Œ ë³´ê°• (ê¸°ì¡´ê°’ ìˆìœ¼ë©´ ì¡´ì¤‘)
if calc_power_cost is not None:
    # calc_power_costë¥¼ all_df ê¸¸ì´ì— ë§ëŠ” ì‹œë¦¬ì¦ˆë¡œ ë³´ì¥
    calc_power_cost = pd.Series(calc_power_cost, index=all_df.index)
    
    if "ì „ë ¥_ë¹„ìš©(ì›)" in all_df.columns:
        s = pd.to_numeric(all_df["ì „ë ¥_ë¹„ìš©(ì›)"], errors="coerce")
        mask = s.isna()
        # ì¸ë±ìŠ¤ ì •ë ¬/ì¬ìƒ‰ì¸ ì—†ì´ "ê°™ì€ ìœ„ì¹˜"ë§Œ ì±„ì›€
        s.loc[mask] = calc_power_cost.loc[mask].values
        all_df["ì „ë ¥_ë¹„ìš©(ì›)"] = s
    else:
        all_df["ì „ë ¥_ë¹„ìš©(ì›)"] = calc_power_cost.values


# ============================================================================
# [ìˆ˜ì •ë¨] Energy ë°ì´í„° ì²˜ë¦¬ (Empty DataFrame ì²´í¬ ì¶”ê°€)
# Modified: Energy ë°ì´í„°ê°€ ë¹„ì–´ìˆì„ ê²½ìš° ì²˜ë¦¬ ê±´ë„ˆë›°ê¸°
# ============================================================================

# Energy ë°ì´í„°ê°€ ìˆì„ ë•Œë§Œ ì²˜ë¦¬
if 'ENERGY_DATA_AVAILABLE' in locals() and ENERGY_DATA_AVAILABLE:
    # --- ë‚ ì§œ ë²”ìœ„ ì„ íƒ (all_df ë¡œë“œ í›„ ë°”ë¡œ) ---
    start_date = all_df["datetime"].min().date()
    end_date   = all_df["datetime"].max().date()

    ì „ì²´ë‚ ì§œë²”ìœ„ = st.date_input(
        "ğŸ“… ë¶„ì„í•  ë‚ ì§œ ë²”ìœ„ ì„ íƒ",
        (start_date, end_date),
        key="ì „ì²´ë‚ ì§œ"
    )
    if isinstance(ì „ì²´ë‚ ì§œë²”ìœ„, (tuple, list)):
        if len(ì „ì²´ë‚ ì§œë²”ìœ„) >= 2:
            ì‹œì‘ = pd.Timestamp(ì „ì²´ë‚ ì§œë²”ìœ„[0])
            ì¢…ë£Œ = pd.Timestamp(ì „ì²´ë‚ ì§œë²”ìœ„[1]) + pd.Timedelta(days=1)
        elif len(ì „ì²´ë‚ ì§œë²”ìœ„) == 1:
            ì‹œì‘ = pd.Timestamp(ì „ì²´ë‚ ì§œë²”ìœ„[0])
            ì¢…ë£Œ = ì‹œì‘ + pd.Timedelta(days=1)
        else:
            ì‹œì‘ = pd.Timestamp(start_date)
            ì¢…ë£Œ = pd.Timestamp(end_date) + pd.Timedelta(days=1)
    else:
        ì‹œì‘ = pd.Timestamp(ì „ì²´ë‚ ì§œë²”ìœ„)
        ì¢…ë£Œ = ì‹œì‘ + pd.Timedelta(days=1)

    # ì´ êµ¬ê°„ì— ë§ê²Œ í•„í„°ë§ëœ df
    all_df_range = all_df[
        (all_df["datetime"] >= ì‹œì‘) &
        (all_df["datetime"] <  ì¢…ë£Œ)
    ].copy()

    # --- ê³µì¡°ê¸°ë³„ ìš”ì•½ (ì´ì œ ê¸°ê°„ ì ìš©) ---
    top_summary_df = make_top_summary(all_df_range)
    st.markdown("### ğŸ“Š ê³µì¡°ê¸°ë³„ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰/ë¹„ìš© ìš”ì•½")
    st.dataframe(top_summary_df, use_container_width=True)

    ê³µì¡°ê¸°ëª©ë¡ = sorted(
        set(df_final_all["ê³µì¡°ê¸°"].dropna().unique())
        | set(all_df["ê³µì¡°ê¸°"].dropna().unique())
    )
    í•­ëª©ëª©ë¡ = get_items_from_final(all_df)
else:
    # Energy ë°ì´í„°ê°€ ì—†ì„ ë•Œì˜ ê¸°ë³¸ê°’ ì„¤ì •
    st.info("ğŸ’¡ Energy ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. Sensor ë°ì´í„°ë§Œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.")
    ê³µì¡°ê¸°ëª©ë¡ = sorted(set(df_final_all["ê³µì¡°ê¸°"].dropna().unique())) if not df_final_all.empty and "ê³µì¡°ê¸°" in df_final_all.columns else []
    í•­ëª©ëª©ë¡ = []
    ì‹œì‘ = pd.to_datetime('2025-01-01')
    ì¢…ë£Œ = pd.to_datetime('2025-12-31')

AHU_RAT_LIMITS = {
    "AHU01": [17.9, 25.1], "AHU02": [17.9, 25.1], "AHU03": [17.9, 25.1], "AHU04": [17.9, 25.1], "AHU05": [17.9, 25.1],
    "AHU06": [17.9, 25.1], "AHU07": [17.9, 25.1], "AHU08": [17.9, 25.1], "AHU09": [17.9, 25.1], "AHU10": [17.9, 25.1],
    "AHU11": [17.9, 25.1], "AHU12": [17.9, 25.1], "AHU13": [17.9, 22.1], "AHU14": [17.9, 25.1], 
    "AHU020": [0.9, 25.1], "AHU021": [0.9, 30.1], "AHU022": [17.9, 25.1], "AHU023": [17.9, 25.1],
    "AHU024": [18, 22], "AHU025": [18, 22], "AHU026": [17.9, 25.1], "AHU27": [17.9, 25.1], 
    "AHU39": [14.9, 25.1], "AHU45": [18, 22]
}

AHU_RAH_LIMITS = {
    "AHU01": [75.1], "AHU02": [75.1], "AHU03": [75.1], "AHU05": [75.1],
    "AHU06": [75.1], "AHU07": [75.1], "AHU09": [75.1], "AHU10": [75.1],
    "AHU11": [75.1], "AHU13": [65.1], "AHU14": [75.1],
    "AHU020": [70.1], "AHU021": [70.1], "AHU022": [75.1],
    "AHU024": [70.1], "AHU025": [70.1], "AHU026": [75.1], "AHU27": [75.1],
    "AHU39": [75.1], "AHU45": [70.1]
}  

# ============================================================================
# [ìˆ˜ì •ë¨] Empty DataFrame ì²´í¬ ì¶”ê°€ (ì—°ë„ ëª©ë¡ ì¶”ì¶œ)
# Modified: Empty DataFrameì¼ ë•Œ ê¸°ë³¸ê°’ ë°˜í™˜
# ============================================================================
ì—°ë„ëª©ë¡ = sorted(all_df["datetime"].dt.year.unique()) if not all_df.empty and "datetime" in all_df.columns else []







def _format_number(v, unit="ì›"):
    if v is None or (isinstance(v, float) and np.isnan(v)):
        return "-"
    try:
        return f"{int(round(float(v))):,}{unit if unit else ''}"
    except Exception:
        return str(v)

def build_gpt_context(ahu, start_dt, end_dt, daily_df, baseline_df, k_sigma, highlight_year, topN_df):
    """
    í˜„ì¬ í™”ë©´ì˜ í•µì‹¬ ê°’ë§Œ ì••ì¶•í•´ì„œ í…ìŠ¤íŠ¸ ì»¨í…ìŠ¤íŠ¸ë¡œ ë§Œë“¤ê¸°.
    - ì¼ìˆ˜/í‰ê· /ì´ˆê³¼í•©ê³„ ë“±
    """
    if daily_df is None or daily_df.empty:
        return f"ê³µì¡°ê¸° {ahu} / {start_dt.date()}~{(end_dt - pd.Timedelta(days=1)).date()} ê¸°ê°„ì— ë°ì´í„° ì—†ìŒ."

    # ê¸°ê°„ ìš”ì•½
    days = daily_df["ë‚ ì§œ"].nunique()
    total_cost = daily_df["ì´ë¹„ìš©(ì›)"].sum()
    exceed_cost = daily_df["ì´ˆê³¼ë¹„ìš©(ì›)"].sum()
    avg_cost = daily_df["ì´ë¹„ìš©(ì›)"].mean()

    # ì—°ë„ë³„ í•©ê³„(ê°„ë‹¨)
    by_year = (
        daily_df.groupby("ì—°ë„")["ì´ë¹„ìš©(ì›)"]
        .sum()
        .sort_index()
        .to_dict()
    )

    # ê¸°ì¤€ì„  ìš”ì•½
    baseline_mean = baseline_df["ê¸°ì¤€ì„ (ì›)"].mean() if not baseline_df.empty else np.nan

    # TopN í‘œ ê°„ë‹¨ ì •ë¦¬
    top_lines = []
    if topN_df is not None and not topN_df.empty:
        for _, r in topN_df.head(5).iterrows():
            top_lines.append(
                f"- {r['ë‚ ì§œ'].date()} | ë¹„ìš© {_format_number(r['ì´ë¹„ìš©(ì›)'])} vs ê¸°ì¤€ì„  {_format_number(r['ê¸°ì¤€ì„ (ì›)'])} â†’ ì´ˆê³¼ {_format_number(r['ì´ˆê³¼ë¹„ìš©(ì›)'])}"
            )

    ctx = []
    ctx.append(f"[ê¸°ë³¸ì •ë³´] ê³µì¡°ê¸°: {ahu}, ê¸°ê°„: {start_dt.date()} ~ {(end_dt - pd.Timedelta(days=1)).date()} (ì¼ìˆ˜: {days}ì¼)")
    ctx.append(f"[ê¸°ì¤€ì„¤ì •] ê¸°ì¤€ = ì›”-ì¼ í‰ê·  + {k_sigma:.1f}Ïƒ, í•˜ì´ë¼ì´íŠ¸ ì—°ë„ = {highlight_year}")
    ctx.append(f"[ì´ê´„] ì´ë¹„ìš©: {_format_number(total_cost)}, ì¼í‰ê· : {_format_number(avg_cost)}, ê¸°ì¤€ì„  í‰ê· : {_format_number(baseline_mean)}, ì ì¬ ì ˆê°(ì´ˆê³¼í•©): {_format_number(exceed_cost)}")
    ctx.append("[ì—°ë„ë³„ ì´ë¹„ìš©] " + ", ".join([f"{y}: {_format_number(v)}" for y, v in by_year.items()]))

    if top_lines:
        ctx.append("[ì´ˆê³¼ Top5]")
        ctx.extend(top_lines)

    return "\n".join(ctx)



íƒ­2, íƒ­3, íƒ­5 = st.tabs(["âš¡ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰/ì†Œëª¨ë¹„ìš© ë¶„ì„", "ê³µì¡°ê¸° ê°„ ì—ë„ˆì§€ ë¶„ì„", "ğŸ“Š í•­ëª© ë¶„ì„"])

with íƒ­2:

    # ============================================================================
    # [ìˆ˜ì •ë¨] Energy ë°ì´í„° ì²´í¬ (íƒ­ ì‹œì‘ ë¶€ë¶„)
    # Modified: Energy ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ë©”ì‹œì§€ í‘œì‹œ í›„ íƒ­ ì¢…ë£Œ
    # ============================================================================
    if not ('ENERGY_DATA_AVAILABLE' in locals() and ENERGY_DATA_AVAILABLE):
        st.warning("âš ï¸ **Energy ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤**")
        st.info("""
        ğŸ’¡ **Energy ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ë ¤ë©´:**

        1. **Parquet ëª¨ë“œ**: `history` í´ë”ì— íŒŒquet íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”

        2. **Database ëª¨ë“œ**: Energy ë°ì´í„° ìë™ ë¡œë“œ
           - **Airflow Webserver** ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”
           - Smart file monitoringì´ ìë™ìœ¼ë¡œ `ahu_readings_staging` â†’ `energy_readings` ETL ì‹¤í–‰
           - Airflow DAG: `etl_sensor_to_energy`ê°€ ì£¼ê¸°ì ìœ¼ë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤

        ğŸ”§ **Airflow ìƒíƒœ í™•ì¸:**
        - Webserver: `http://localhost:8080`
        - CLI: `airflow dags list`
        - Logs: `airflow logs etl_sensor_to_energy --last 1`

        ğŸ”§ **ìˆ˜ë™ ETL (Airflowê°€ ì‹¤í–‰ë˜ì§€ ì•Šì„ ë•Œ):**
        ```sql
        -- ahu_monitoring DBì—ì„œ ì‹¤í–‰
        INSERT INTO ahu_data.energy_readings (timestamp, ahu_id, metric_name, value, unit)
        SELECT
            timestamp,
            ahu_id,
            CASE
                WHEN í•­ëª©ëª… IN ('CCV', 'PC_CCV') THEN 'ccv_cold_water_kwh'
                WHEN í•­ëª©ëª… IN ('HCV', 'DH_HCV') THEN 'hcv_steam_kwh'
                WHEN í•­ëª©ëª… = 'SFST' THEN 'ac_sf_electricity_kwh'
                ELSE 'other'
            END as metric_name,
            SUM(ê°’) as value,
            'kWh' as unit
        FROM ahu_data.ahu_readings_staging
        WHERE í•­ëª©ëª… IN ('CCV', 'PC_CCV', 'HCV', 'DH_HCV', 'SFST')
        GROUP BY timestamp, ahu_id,
                 CASE WHEN í•­ëª©ëª… IN ('CCV', 'PC_CCV') THEN 'ccv_cold_water_kwh'
                      WHEN í•­ëª©ëª… IN ('HCV', 'DH_HCV') THEN 'hcv_steam_kwh'
                      WHEN í•­ëª©ëª… = 'SFST' THEN 'ac_sf_electricity_kwh'
                      ELSE 'other' END;
        ```
        """)
        st.success("âœ… **Sensor ë°ì´í„°ëŠ” ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤!**")
        st.info("ğŸ’¡ Sensor ë°ì´í„° ë¶„ì„ì€ ë‹¤ë¥¸ íƒ­ì„ ì´ìš©í•´ì£¼ì„¸ìš”.")
        st.stop()

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ğŸ¤– GPT ì¸ì‚¬ì´íŠ¸ íŒ¨ë„ (íƒ­2ì˜ ë§¨ ìœ„ë¡œ ì´ë™!)
    with st.sidebar:
        st.header("ğŸ§  ChatGPT ì¸ì‚¬ì´íŠ¸")
        st.caption(f"ëª¨ë¸: `{GPT_MODEL}`")

        # ì…ë ¥ì¹¸/ë²„íŠ¼ì€ í•­ìƒ ë Œë”ë§, í‚¤ ì—†ìœ¼ë©´ ë¹„í™œì„±í™”
        user_q = st.text_area(
            "ì§ˆë¬¸ ì…ë ¥",
            placeholder="ì˜ˆ: ì—¬ë¦„ì²  ëƒ‰ìˆ˜ë¹„ìš© ê¸‰ë“± ì›ì¸ì€?",
            height=80,
            key="gpt_q",
            disabled=(gpt_client is None),
        )
        col1, col2 = st.columns(2)
        gen_clicked = col1.button("ğŸ” GPT ì¸ì‚¬ì´íŠ¸ ìƒì„±", use_container_width=True,
                                key="gen_insight_btn", disabled=(gpt_client is None))
        ask_clicked = col2.button("ì§ˆë¬¸ ë³´ë‚´ê¸°", use_container_width=True,
                                key="ask_gpt_btn", disabled=(gpt_client is None))

        if gpt_client is None:
            st.info("API í‚¤ê°€ ì—†ì–´ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ê±°ë‚˜ gpt_client ì´ˆê¸°í™”ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        else:
            # ì»¨í…ìŠ¤íŠ¸ëŠ” í´ë¦­ ì‹œì ì— 'ìˆëŠ” ê°’ë§Œ' ì•ˆì „í•˜ê²Œ êµ¬ì„±
            def _safe_ctx():
                return build_gpt_context(
                    ahu=st.session_state.get("ì„ íƒê³µì¡°ê¸°_íƒ­", "ë¯¸ì„ íƒ"),
                    start_dt=locals().get("ì‹œì‘", pd.Timestamp.now()) if "ì‹œì‘" in locals() else pd.Timestamp.now(),
                    end_dt=locals().get("ì¢…ë£Œ", pd.Timestamp.now()),
                    daily_df=locals().get("daily", pd.DataFrame()),
                    baseline_df=locals().get("ref", pd.DataFrame()),
                    k_sigma=locals().get("k_sigma", 1.0),
                    highlight_year=locals().get("highlight_year", None),
                    topN_df=locals().get("topN", pd.DataFrame()),
                )

            if gen_clicked:
                with st.spinner("GPTê°€ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                    ctx_text = _safe_ctx()
                    msgs = [
                        {"role": "system", "content":
                            "ë„ˆëŠ” ê³µì¡°ê¸° ì—ë„ˆì§€/ë¹„ìš© ë°ì´í„° ë¶„ì„ê°€ì•¼. "
                            "ìš”ì•½ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì´ìƒ ì›ì¸, ì ˆê° í¬ì¸íŠ¸, ê³„ì ˆ íŠ¸ë Œë“œë¥¼ ë³´ìˆ˜ì ìœ¼ë¡œ bulletë¡œ ì •ë¦¬í•´."},
                        {"role": "user", "content": f"ì»¨í…ìŠ¤íŠ¸:\n{ctx_text}\n\nìš”ì²­: í•µì‹¬ ì¸ì‚¬ì´íŠ¸ 5ê°œ + ê¶Œì¥ í›„ì† ë¶„ì„ 2ê°œ."}
                    ]
                    try:
                        resp = gpt_client.chat.completions.create(
                            model=GPT_MODEL, messages=msgs, temperature=0.3, max_tokens=700
                        )
                        st.markdown(resp.choices[0].message.content)
                    except Exception as e:
                        st.error(f"GPT í˜¸ì¶œ ì˜¤ë¥˜: {e}")

            if ask_clicked:
                if not user_q.strip():
                    st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.")
                else:
                    with st.spinner("GPTê°€ ë‹µë³€ ì¤‘..."):
                        ctx_text = _safe_ctx()
                        msgs = [
                            {"role": "system", "content": "ë„ˆëŠ” ê³µì¡°ê¸° ì—ë„ˆì§€/ë¹„ìš© ë°ì´í„° ë¶„ì„ê°€ì•¼. ê°„ê²°í•˜ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ë‹µë³€ì„ í•´."},
                            {"role": "user", "content": f"ë°°ê²½ ìš”ì•½:\n{ctx_text}\n\nì§ˆë¬¸:\n{user_q}"}
                        ]
                        try:
                            resp = gpt_client.chat.completions.create(
                                model=GPT_MODEL, messages=msgs, temperature=0.3, max_tokens=600
                            )
                            st.markdown(resp.choices[0].message.content)
                        except Exception as e:
                            st.error(f"GPT í˜¸ì¶œ ì˜¤ë¥˜: {e}")
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€



    # 2) ê³µì¡°ê¸° ì„ íƒ (íƒ­ ì•ˆìª½, ë‚ ì§œ ë°‘)
    # [ìˆ˜ì •ë¨] Empty DataFrame ì²´í¬ ì¶”ê°€
    ahu_set = set()
    if not df_final_all.empty and "ê³µì¡°ê¸°" in df_final_all.columns:
        ahu_set.update(df_final_all["ê³µì¡°ê¸°"].dropna().unique())
    if not all_df.empty and "ê³µì¡°ê¸°" in all_df.columns:
        ahu_set.update(all_df["ê³µì¡°ê¸°"].dropna().unique())

    ê³µì¡°ê¸°ëª©ë¡ = sorted(ahu_set) if ahu_set else ["AHU01"]
    ì„ íƒê³µì¡°ê¸° = st.selectbox("ğŸ“Œ ë¶„ì„í•  ê³µì¡°ê¸° ì„ íƒ", ê³µì¡°ê¸°ëª©ë¡, index=0, key="ì„ íƒê³µì¡°ê¸°_íƒ­")

    # 3) ì„ íƒëœ ê³µì¡°ê¸° ë°ì´í„° í•„í„°ë§
    # [ìˆ˜ì •ë¨] Empty DataFrame ì²´í¬ ì¶”ê°€
    if not all_df.empty and "ê³µì¡°ê¸°" in all_df.columns and "datetime" in all_df.columns:
        df_ahu = all_df[
            (all_df["ê³µì¡°ê¸°"] == ì„ íƒê³µì¡°ê¸°) &
            (all_df["datetime"] >= ì‹œì‘) &
            (all_df["datetime"] < ì¢…ë£Œ)
        ].copy()
    else:
        df_ahu = pd.DataFrame()

    if df_ahu.empty:
        st.error("í•´ë‹¹ ê³µì¡°ê¸°ì˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    # 4) ê³µì¡°ê¸° í˜•ì‹ í‘œì‹œ
    ahu_í˜•ì‹ = "ì¼ë°˜í˜•"
    if ì„ íƒê³µì¡°ê¸° in ê±´ì‹ì œìŠµí˜•_ê³µì¡°ê¸°:
        ahu_í˜•ì‹ = "ê±´ì‹ì œìŠµí˜•"
    elif ì„ íƒê³µì¡°ê¸° in ëƒ‰ê°ì œìŠµí˜•_ê³µì¡°ê¸°:
        ahu_í˜•ì‹ = "ëƒ‰ê°ì œìŠµí˜•"
    st.caption(f"ğŸ“˜ í˜„ì¬ ì„ íƒëœ ê³µì¡°ê¸° í˜•ì‹: {ahu_í˜•ì‹}")

    # 5) ì£¼ìš” í•­ëª© ë°˜ë³µ ì‹œê°í™”
    raw = load_ahu_detail_by_mode(ì„ íƒê³µì¡°ê¸°, mode)
    for ì„ íƒí•­ëª© in ["CCV", "PC_CCV", "HCV", "DH_HCV", "RAT", "RAH"]:
        if not raw.empty:
            df_selected = raw[raw["í•­ëª©ëª…"] == ì„ íƒí•­ëª©].copy()
            if df_selected.empty:
                continue
            # ğŸ‘‰ ì—¬ê¸°ì„œ ê·¸ë˜í”„ í•¨ìˆ˜ í˜¸ì¶œ

    st.subheader("ğŸ’¸ ì—ë„ˆì§€ ë¹„ìš© ë° ì¼ì¼ ë¹„ìš© íŠ¸ë Œë“œ")

    ahu = ì„ íƒê³µì¡°ê¸°

    # â–· ê¸°ì¤€ ìƒí–¥ ì˜µì…˜ (í•˜ì´ë¼ì´íŠ¸ ì„ íƒ ì œê±°)
    k_sigma = st.slider("ê¸°ì¤€ ìƒí–¥: í‰ê·  + KÂ·Ïƒ (K)", min_value=0.0, max_value=3.0, value=1.5, step=0.1)
    st.metric("ê¸°ì¤€ (ì›”-ì¼ í‰ê·  + KÂ·Ïƒ)", f"K = {k_sigma:.1f}")

    # 1) ì„ íƒ ê¸°ê°„ + ê³µì¡°ê¸° í•„í„°
    df_sel = all_df[
        (all_df["ê³µì¡°ê¸°"] == ahu) &
        (all_df["datetime"] >= ì‹œì‘) &
        (all_df["datetime"] <  ì¢…ë£Œ)
    ].copy()

    if df_sel.empty:
        st.info("í•´ë‹¹ ê¸°ê°„ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        # 2) ì¼ì¼ ì´ë¹„ìš©(ì›)
        cost_cols = [c for c in ["ì „ë ¥_ë¹„ìš©(ì›)","ë¹„ìš©(ì›)_CCV","ë¹„ìš©(ì›)_PC_CCV","ë¹„ìš©(ì›)_HCV","ë¹„ìš©(ì›)_DH_HCV"] if c in df_sel.columns]
        if not cost_cols:
            st.info("ë¹„ìš© ì»¬ëŸ¼ì´ ì—†ì–´ ì ˆê°ë¶„ ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        else:
            df_sel[cost_cols] = df_sel[cost_cols].apply(pd.to_numeric, errors="coerce").fillna(0)
            df_sel["ë‚ ì§œ"] = df_sel["datetime"].dt.normalize()
            daily = df_sel.groupby("ë‚ ì§œ", as_index=False)[cost_cols].sum()
            daily["ì´ë¹„ìš©(ì›)"] = daily[cost_cols].sum(axis=1)

            # (ì„ íƒ) kWh
            kwh_cols = [c for c in ["kWh_CCV","kWh_PC_CCV","kWh_HCV","kWh_DH_HCV"] if c in df_sel.columns]
            if kwh_cols:
                df_sel[kwh_cols] = df_sel[kwh_cols].apply(pd.to_numeric, errors="coerce").fillna(0)
                daily_kwh = df_sel.groupby("ë‚ ì§œ", as_index=False)[kwh_cols].sum()
                daily_kwh["ì´kWh"] = daily_kwh[kwh_cols].sum(axis=1)
                daily = daily.merge(daily_kwh[["ë‚ ì§œ","ì´kWh"]], on="ë‚ ì§œ", how="left")
            else:
                daily["ì´kWh"] = np.nan

            # 3) í‚¤/ì •ë ¬ìš© ì›”-ì¼ ë¬¸ìì—´ (xì¶•ì€ í•­ìƒ 01-01 ~ 12-31)
            daily["ì—°ë„"] = pd.to_datetime(daily["ë‚ ì§œ"]).dt.year
            daily["ì›”ì¼"] = pd.to_datetime(daily["ë‚ ì§œ"]).dt.strftime("%m-%d")

            # ëª¨ë“  ì›”ì¼ ìˆœì„œ ê³ ì • (ì¹´í…Œê³ ë¦¬ ì¶•ìš©)
            monthday_order = pd.date_range("2000-01-01", "2000-12-31", freq="D").strftime("%m-%d").tolist()
            # ì›”ë³„ ëˆˆê¸ˆ(1ì¼ë§Œ)
            month_ticks = pd.date_range("2000-01-01", "2000-12-01", freq="MS").strftime("%m-%d").tolist()

            # 4) ê¸°ì¤€ì„ : ì›”-ì¼ í‰ê·  + KÏƒ
            ref = daily.groupby("ì›”ì¼", as_index=False).agg(
                í‰ê· ë¹„ìš©=("ì´ë¹„ìš©(ì›)", "mean"),
                í‘œì¤€í¸ì°¨=("ì´ë¹„ìš©(ì›)", "std"),
                ìƒ˜í”Œìˆ˜=("ì´ë¹„ìš©(ì›)", "count")
            )
            ref["ê¸°ì¤€ì„ (ì›)"] = ref["í‰ê· ë¹„ìš©"] + k_sigma * ref["í‘œì¤€í¸ì°¨"].fillna(0)

            # ë³‘í•© & ì´ˆê³¼ë¶„
            daily = daily.merge(ref[["ì›”ì¼","ê¸°ì¤€ì„ (ì›)"]], on="ì›”ì¼", how="left")
            daily["ì´ˆê³¼ë¹„ìš©(ì›)"] = (daily["ì´ë¹„ìš©(ì›)"] - daily["ê¸°ì¤€ì„ (ì›)"]).clip(lower=0)

            # ìš”ì•½ í‘œì‹œ
            st.metric("ì ì¬ ì ˆê°ë¹„ìš© (í•©ê³„)", f"{int(round(float(daily['ì´ˆê³¼ë¹„ìš©(ì›)'].sum()))):,} ì›")
            if daily["ì´kWh"].notna().any():
                ref_e = daily.groupby("ì›”ì¼", as_index=False).agg(í‰ê· kWh=("ì´kWh","mean"), í‘œì¤€í¸ì°¨kWh=("ì´kWh","std"))
                ref_e["ê¸°ì¤€kWh"] = ref_e["í‰ê· kWh"] + k_sigma * ref_e["í‘œì¤€í¸ì°¨kWh"].fillna(0)
                daily = daily.merge(ref_e[["ì›”ì¼","ê¸°ì¤€kWh"]], on="ì›”ì¼", how="left")
                daily["ì´ˆê³¼kWh"] = (daily["ì´kWh"] - daily["ê¸°ì¤€kWh"]).clip(lower=0)
                st.metric("ì ì¬ ì ˆê°ì—ë„ˆì§€ (í•©ê³„)", f"{int(round(float(daily['ì´ˆê³¼kWh'].sum()))):,} kWh")
            else:
                st.metric("ì ì¬ ì ˆê°ì—ë„ˆì§€ (í•©ê³„)", "â€”")

            # 5) ê·¸ë˜í”„: ì—°ë„ ë¼ì¸ + ê¸°ì¤€ì„  + ê° ì—°ë„ ì´ˆê³¼ êµ¬ê°„ ìë™ ìŒì˜
            # ë¼ì¸
            # â”€â”€ ê¸°ì¤€ì¹˜/ë¼ì¸/ìŒì˜ ê·¸ë˜í”„ (ì›”ì¼ ê¸°ì¤€, 1~12ì›” xì¶• ê³ ì • ì •ë ¬) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # daily: [ë‚ ì§œ, ì›”ì¼("MM-DD"), ì—°ë„, ì´ë¹„ìš©(ì›), ê¸°ì¤€ì„ (ì›)] ê°€ ìˆì–´ì•¼ í•¨

            # 1) ì›”ì¼ ì¹´í…Œê³ ë¦¬ ì •ë ¬ ë°°ì—´ (ìœ¤ë…„ í¬í•¨ 366ì¼ ëŒ€ë¹„)
            ì›”ì¼_ì •ë ¬ = pd.date_range("2001-01-01", "2001-12-31", freq="D").strftime("%m-%d").tolist()

            # â”€â”€ 7) ì—°ë„ ê²¹ì³ë³´ê¸° + ì—°ë„ë³„ ì´ˆê³¼êµ¬ê°„ ìŒì˜(ê¸°ì¤€ì„  ëŒ€ë¹„) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            pivot = daily.pivot_table(index="ì›”ì¼", columns="ì—°ë„", values="ì´ë¹„ìš©(ì›)", aggfunc="sum")
            pivot = pivot[[c for c in [2021, 2022, 2023, 2024, 2025] if c in pivot.columns]]
            if pivot.empty:
                st.info("ê·¸ë˜í”„ë¡œ í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                # â‘  ëª¨ë“  ì—°ë„ ë¼ì¸ (ê²¹ì³ë³´ê¸°)
                plot_df = pivot.reset_index().melt(id_vars="ì›”ì¼", var_name="ì—°ë„", value_name="ì´ë¹„ìš©(ì›)")
                # xì¶• ì›”-ì¼ ê³ ì • ìˆœì„œ
                monthday_order = sorted(plot_df["ì›”ì¼"].unique())
                fig = px.line(
                    plot_df.sort_values(["ì—°ë„", "ì›”ì¼"]),
                    x="ì›”ì¼", y="ì´ë¹„ìš©(ì›)", color=plot_df["ì—°ë„"].astype(str),
                    title=f"{ahu} | ì—°ë„ ê²¹ì³ë³´ê¸° (ì¼ì¼ ì´ë¹„ìš©, ê¸°ì¤€ì„ ={k_sigma:.1f}Ïƒ)",
                    markers=False
                )
                fig.update_layout(
                    xaxis=dict(
                        tickangle=-45,
                        categoryorder="array",
                        categoryarray=monthday_order
                    )
                )

                # â‘¡ ê¸°ì¤€ì„ (ì›”-ì¼ í‰ê·  + KÏƒ) ë¼ì¸
                baseline_df = ref.sort_values("ì›”ì¼")
                fig.add_scatter(
                    x=baseline_df["ì›”ì¼"], y=baseline_df["ê¸°ì¤€ì„ (ì›)"],
                    mode="lines", name="ê¸°ì¤€ì„ (í‰ê· +KÂ·Ïƒ)", line=dict(dash="dash"),
                    hoverinfo="skip"
                )

                # â”€â”€ ë³´ì¡°: ìƒ‰ì„ ì•ŒíŒŒê°’ì´ ìˆëŠ” rgbaë¡œ ë°”ê¾¸ëŠ” ìœ í‹¸ â”€â”€
                def _to_rgba(color: str, alpha: float = 0.25) -> str:
                    if not isinstance(color, str):
                        return color
                    c = color.strip()
                    if c.startswith("rgba("):
                        # rgba(â€¦, a) â†’ aë§Œ êµì²´
                        body = c[5:-1]
                        parts = [p.strip() for p in body.split(",")]
                        if len(parts) == 4:
                            parts[-1] = str(alpha)
                            return "rgba(" + ", ".join(parts) + ")"
                        return c
                    if c.startswith("rgb("):
                        # rgb(r,g,b) â†’ rgba(r,g,b,alpha)
                        return c.replace("rgb(", "rgba(").replace(")", f", {alpha})")
                    # ê·¸ ì™¸(#ìƒ‰ìƒ ë“±)ëŠ” ê·¸ëŒ€ë¡œ ì‚¬ìš©
                    return c

                # â‘¢ ì—°ë„ë³„ ì´ˆê³¼êµ¬ê°„ ìŒì˜ â€” ë¶ˆì—°ì† êµ¬ê°„(run) ë‹¨ìœ„ë¡œ ì˜ì—­ ì±„ìš°ê¸°
                def add_exceed_fill_for_year(fig, df_year, year, color):
                    if not {"ì›”ì¼", "ì´ë¹„ìš©(ì›)"}.issubset(df_year.columns):
                        return

                    d = df_year.copy()
                    d = d.sort_values("ì›”ì¼")

                    # ê¸°ì¤€ì„  ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì´ ì—°ë„ ìì²´ì˜ ì›”-ì¼ í‰ê· ìœ¼ë¡œ ìƒì„±
                    if "ê¸°ì¤€ì„ (ì›)" not in d.columns:
                        base = d.groupby("ì›”ì¼")["ì´ë¹„ìš©(ì›)"].mean()
                        d["ê¸°ì¤€ì„ (ì›)"] = d["ì›”ì¼"].map(base)

                    # â¬‡â¬‡ ì—¬ê¸°ë¶€í„° ìˆ˜ì •ëœ ë¶€ë¶„ â¬‡â¬‡
                    # ì´ˆê³¼ ì—¬ë¶€ (pyarrow â†’ ì¼ë°˜ boolë¡œ ë³€í™˜)
                    over = (d["ì´ë¹„ìš©(ì›)"] > d["ê¸°ì¤€ì„ (ì›)"]).astype("bool")
                    if not over.any():
                        return

                    # êµ¬ê°„ì´ ë°”ë€ŒëŠ” ì§€ì : bool â†’ int64ë¡œ ë°”ê¿”ì„œ cumsum
                    change = (over != over.shift()).astype("int64")
                    run = change.cumsum()
                    # â¬†â¬† ì—¬ê¸°ê¹Œì§€ ìˆ˜ì •ëœ ë¶€ë¶„ â¬†â¬†

                    shown = False
                    for _, g in d[over].groupby(run):
                        if g.empty:
                            continue

                        # ê¸°ì¤€ì„  ë¼ì¸ (íˆ¬ëª…, fill ê¸°ë°˜)
                        fig.add_scatter(
                            x=g["ì›”ì¼"],
                            y=g["ê¸°ì¤€ì„ (ì›)"],
                            mode="lines",
                            line=dict(width=0),
                            showlegend=False,
                            hoverinfo="skip",
                            connectgaps=False,
                        )

                        # ì´ˆê³¼ êµ¬ê°„ ì±„ìš°ê¸°
                        fig.add_scatter(
                            x=g["ì›”ì¼"],
                            y=g["ì´ë¹„ìš©(ì›)"],
                            mode="lines",
                            line=dict(width=0),
                            fill="tonexty",
                            connectgaps=False,
                            name=f"{year} ì´ˆê³¼êµ¬ê°„(ì ˆê°ê°€ëŠ¥)",
                            fillcolor=_to_rgba(color, 0.25),
                            showlegend=not shown,
                        )
                        shown = True


                # plotlyê°€ ìë™ ë°°ì •í•œ ì„ ìƒ‰ì„ ì¬ì‚¬ìš©
                color_map = {
                    trace.name: getattr(trace.line, "color", None)
                    for trace in fig.data
                    if getattr(trace, "mode", "") == "lines" and trace.name not in ["ê¸°ì¤€ì„ (í‰ê· +KÂ·Ïƒ)"]
                }

                # ì—°ë„ë³„ë¡œ ì´ˆê³¼êµ¬ê°„ ì±„ìš°ê¸°
                for y in sorted(daily["ì—°ë„"].unique()):
                    d_y = daily[daily["ì—°ë„"] == y].copy()
                    if d_y.empty:
                        continue

                    # í˜¹ì‹œë¼ë„ ê¸°ì¤€ì„  ì»¬ëŸ¼ì´ ë¹ ì ¸ ìˆìœ¼ë©´ refì—ì„œ ë‹¤ì‹œ ë¶™ì—¬ì¤Œ
                    if "ê¸°ì¤€ì„ (ì›)" not in d_y.columns and "ê¸°ì¤€ì„ (ì›)" in ref.columns:
                        d_y = d_y.merge(ref[["ì›”ì¼", "ê¸°ì¤€ì„ (ì›)"]], on="ì›”ì¼", how="left")

                    c = color_map.get(str(y), "rgb(200,200,200)")
                    add_exceed_fill_for_year(fig, d_y, y, c)

                st.plotly_chart(fig, use_container_width=True)


    # ========================================================================

    # âœ… final_analysis parquet ê¸°ë°˜ ë°ì´í„°ë§Œ ì‚¬ìš©
    # [ìˆ˜ì •ë¨] Empty DataFrame ì²´í¬ ì¶”ê°€
    if not df_final_all.empty and "ê³µì¡°ê¸°" in df_final_all.columns and "datetime" in df_final_all.columns:
        df_ahu_final = df_final_all[
            (df_final_all["ê³µì¡°ê¸°"] == ì„ íƒê³µì¡°ê¸°)
            & (df_final_all["datetime"] >= ì‹œì‘)
            & (df_final_all["datetime"] < ì¢…ë£Œ)
        ].copy()
    else:
        df_ahu_final = pd.DataFrame()

    if df_ahu_final.empty:
        st.warning("í•´ë‹¹ ê¸°ê°„ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()


    st.subheader("ğŸŒ¤ï¸ ì™¸ê¸° ì¡°ê±´ ê¸°ë°˜ ìœ ì‚¬ì¼(Nearest Day) ë¹„êµ")

    # 0) ì™¸ê¸° ì¼í‰ê·  (ì¼ì ë‹¨ìœ„)
    if ì™¸ê¸°df_daily is None or ì™¸ê¸°df_daily.empty:
        st.info("ì™¸ê¸°(ì¼í‰ê· ) ë°ì´í„°ê°€ ì—†ì–´ ìœ ì‚¬ì¼ ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        st.stop()

    oa_daily = ì™¸ê¸°df_daily.copy()
    oa_daily["ë‚ ì§œ"] = oa_daily["datetime"].dt.normalize()
    oa_daily["ì—°ë„"] = oa_daily["ë‚ ì§œ"].dt.year

    # 1) AHU ì¼ì¼ ì´ë¹„ìš©/ì´kWh ê³„ì‚° (ì„ íƒ ê¸°ê°„ + ì„ íƒ ê³µì¡°ê¸°)
    # [ìˆ˜ì •ë¨] Empty DataFrame ì²´í¬ ì¶”ê°€
    if not all_df.empty and "ê³µì¡°ê¸°" in all_df.columns and "datetime" in all_df.columns:
        df_sel = all_df[
            (all_df["ê³µì¡°ê¸°"] == ì„ íƒê³µì¡°ê¸°) &
            (all_df["datetime"] >= ì‹œì‘) &
            (all_df["datetime"] <  ì¢…ë£Œ)
        ].copy()
    else:
        df_sel = pd.DataFrame()

    if df_sel.empty:
        st.info("ì„ íƒí•œ ê³µì¡°ê¸°ì˜ í•´ë‹¹ ê¸°ê°„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    cost_cols = [c for c in ["ì „ë ¥_ë¹„ìš©(ì›)","ë¹„ìš©(ì›)_CCV","ë¹„ìš©(ì›)_PC_CCV","ë¹„ìš©(ì›)_HCV","ë¹„ìš©(ì›)_DH_HCV"] if c in df_sel.columns]
    if not cost_cols:
        st.info("ë¹„ìš© ì»¬ëŸ¼ì´ ì—†ì–´ ìœ ì‚¬ì¼ ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        st.stop()

    df_sel[cost_cols] = df_sel[cost_cols].apply(pd.to_numeric, errors="coerce").fillna(0)
    df_sel["ë‚ ì§œ"] = df_sel["datetime"].dt.normalize()

    daily_cost = df_sel.groupby("ë‚ ì§œ", as_index=False)[cost_cols].sum()
    daily_cost["ì´ë¹„ìš©(ì›)"] = daily_cost[cost_cols].sum(axis=1)

    kwh_cols = [c for c in ["kWh_CCV","kWh_PC_CCV","kWh_HCV","kWh_DH_HCV"] if c in df_sel.columns]
    if kwh_cols:
        df_sel[kwh_cols] = df_sel[kwh_cols].apply(pd.to_numeric, errors="coerce").fillna(0)
        daily_kwh = df_sel.groupby("ë‚ ì§œ", as_index=False)[kwh_cols].sum()
        daily_kwh["ì´kWh"] = daily_kwh[kwh_cols].sum(axis=1)
        daily = daily_cost.merge(daily_kwh[["ë‚ ì§œ","ì´kWh"]], on="ë‚ ì§œ", how="left")
    else:
        daily = daily_cost.assign(ì´kWh=np.nan)

    daily["ì—°ë„"] = daily["ë‚ ì§œ"].dt.year

    # 2) íƒ€ê²Ÿ ì™¸ê¸° ì¡°ê±´ ì…ë ¥ (ì˜¤ëŠ˜ê°’ ìë™ or ìˆ˜ë™)
    c1, c2, c3 = st.columns([1,1,2])
    with c1:
        ëª¨ë“œ = st.radio("íƒ€ê²Ÿ ì™¸ê¸° ì¡°ê±´", ["ì˜¤ëŠ˜ê°’ ì‚¬ìš©", "ì§ì ‘ ì…ë ¥"], horizontal=True)
    if ëª¨ë“œ == "ì˜¤ëŠ˜ê°’ ì‚¬ìš©":
        # oa_daily ê°€ì¥ ìµœì‹  ë‚ ì§œì˜ í‰ê· ì„ ì‚¬ìš©
        last_row = oa_daily.sort_values("ë‚ ì§œ").tail(1)
        target_T = float(last_row["ì™¸ê¸°ì˜¨ë„"].iloc[0]) if not last_row.empty else 23.0
        target_H = float(last_row["ì™¸ê¸°ìŠµë„"].iloc[0]) if not last_row.empty else 57.0
    else:
        with c2:
            target_T = st.number_input("íƒ€ê²Ÿ ì™¸ê¸°ì˜¨ë„(â„ƒ)", value=23.0, step=0.1, format="%.1f")
        with c3:
            target_H = st.number_input("íƒ€ê²Ÿ ì™¸ê¸°ìŠµë„(%)", value=57.0, step=0.1, format="%.1f")

    c4, c5, c6 = st.columns([1,1,2])
    with c4:
        metric = st.selectbox("ë¹„êµ ì§€í‘œ", ["ì´ë¹„ìš©(ì›)","ì´kWh"])
    with c5:
        # [ìˆ˜ì •ë¨] Empty DataFrame ì²´í¬ ì¶”ê°€
        if not all_df.empty and "datetime" in all_df.columns:
            year_min = int(all_df["datetime"].dt.year.min())
            year_max = int(all_df["datetime"].dt.year.max())
            years = list(range(year_min, year_max+1))
        else:
            years = [2025]
        ì„ íƒì—°ë„ = st.multiselect("ë¹„êµ ì—°ë„", years, default=[y for y in range(2021, 2026) if y in years])
    with c6:
        ë°©ë²• = st.radio("ì„ ì • ë°©ì‹", ["ê°€ê¹Œìš´ 1ì¼(ê±°ë¦¬ ìµœì†Œ)","í—ˆìš© ì˜¤ì°¨ ë‚´ í‰ê· "], horizontal=True)

    # í—ˆìš© ì˜¤ì°¨ ì„¤ì •(ì„ íƒ)
    tol_col1, tol_col2 = st.columns(2)
    with tol_col1:
        tol_T = st.number_input("í—ˆìš© ì˜¤ì°¨(ì˜¨ë„, â„ƒ)", value=1.0, step=0.1, format="%.1f")
    with tol_col2:
        tol_H = st.number_input("í—ˆìš© ì˜¤ì°¨(ìŠµë„, %)", value=5.0, step=0.1, format="%.1f")

    # 3) ìœ ì‚¬ì¼ ë§¤ì¹­ í•¨ìˆ˜
    def pick_similar_by_year(oa_daily_df, target_T, target_H, years, method="nearest", tol_T=1.0, tol_H=5.0):
        """
        method:
          - 'nearest' : ì—°ë„ë³„ë¡œ ê±°ë¦¬(ì˜¨ë„/ìŠµë„ ì°¨ì´ ì œê³±í•©) ê°€ì¥ ì‘ì€ 1ì¼ ì„ íƒ
          - 'tolerance_mean' : tol ë²”ìœ„(ì˜¨ë„/ìŠµë„) ì•ˆì˜ ë‚ ì§œë“¤ í‰ê·  ì‚¬ìš©
        """
        results = []
        for y in years:
            cand = oa_daily_df[oa_daily_df["ì—°ë„"] == y].copy()
            if cand.empty: 
                continue

            cand["dT"] = cand["ì™¸ê¸°ì˜¨ë„"] - target_T
            cand["dH"] = cand["ì™¸ê¸°ìŠµë„"] - target_H
            # ê°„ë‹¨í•œ ê°€ì¤‘ ìœ í´ë¦¬ë“œ ê±°ë¦¬(ì •ê·œí™” ì—†ì´)
            cand["dist"] = np.sqrt(cand["dT"]**2 + (cand["dH"]/2.0)**2)  # ìŠµë„ ì˜í–¥ ì¡°ê¸ˆ ë‚®ì¶¤

            if method == "nearest":
                row = cand.loc[cand["dist"].idxmin()]
                results.append({
                    "ì—°ë„": y,
                    "ë‚ ì§œ": row["ë‚ ì§œ"],
                    "ì™¸ê¸°ì˜¨ë„": row["ì™¸ê¸°ì˜¨ë„"],
                    "ì™¸ê¸°ìŠµë„": row["ì™¸ê¸°ìŠµë„"],
                    "dist": row["dist"],
                    "ì„ ì •ë°©ì‹": "ê°€ê¹Œìš´ 1ì¼"
                })
            else:
                subset = cand[(cand["dT"].abs() <= tol_T) & (cand["dH"].abs() <= tol_H)]
                if subset.empty:
                    # ì˜¤ì°¨ë‚´ê°€ ì—†ìœ¼ë©´ ìµœê·¼ì ‘ 1ì¼ë¡œ ëŒ€ì²´
                    row = cand.loc[cand["dist"].idxmin()]
                    results.append({
                        "ì—°ë„": y,
                        "ë‚ ì§œ": row["ë‚ ì§œ"],
                        "ì™¸ê¸°ì˜¨ë„": row["ì™¸ê¸°ì˜¨ë„"],
                        "ì™¸ê¸°ìŠµë„": row["ì™¸ê¸°ìŠµë„"],
                        "dist": row["dist"],
                        "ì„ ì •ë°©ì‹": "ìµœê·¼ì ‘(ëŒ€ì²´)"
                    })
                else:
                    row = subset.sort_values("dist").head(1).iloc[0]
                    # í‰ê· ì¹˜ë„ ê°™ì´ ì œê³µ(ì„ íƒì¼ í¬í•¨)
                    results.append({
                        "ì—°ë„": y,
                        "ë‚ ì§œ": row["ë‚ ì§œ"],
                        "ì™¸ê¸°ì˜¨ë„": subset["ì™¸ê¸°ì˜¨ë„"].mean(),
                        "ì™¸ê¸°ìŠµë„": subset["ì™¸ê¸°ìŠµë„"].mean(),
                        "dist": subset["dist"].mean(),
                        "ì„ ì •ë°©ì‹": f"ì˜¤ì°¨ë‚´ í‰ê· ({len(subset)}ì¼)"
                    })
        return pd.DataFrame(results)

    method_key = "nearest" if ë°©ë²• == "ê°€ê¹Œìš´ 1ì¼(ê±°ë¦¬ ìµœì†Œ)" else "tolerance_mean"
    picked = pick_similar_by_year(oa_daily, target_T, target_H, ì„ íƒì—°ë„, method=method_key, tol_T=tol_T, tol_H=tol_H)

    if picked.empty:
        st.info("ì„ íƒëœ ì—°ë„ì—ì„œ ìœ ì‚¬í•œ ì™¸ê¸°ì¡°ê±´ì˜ ë‚ ì§œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        st.stop()

    # 4) ìœ ì‚¬ì¼ê³¼ AHU ì¼ì¼ ì§€í‘œ(ì´ë¹„ìš©/ì´kWh) ê²°í•©
    merged = picked.merge(daily[["ë‚ ì§œ","ì—°ë„",metric]], on=["ë‚ ì§œ","ì—°ë„"], how="left")
    merged = merged.dropna(subset=[metric])  # ì§€í‘œ ì—†ëŠ” ë‚  ì œê±°
    merged = merged.sort_values("ì—°ë„")

    # 5) ì‹œê°í™”
    title = f"{ì„ íƒê³µì¡°ê¸°} | íƒ€ê²Ÿ ì™¸ê¸° {target_T:.1f}â„ƒ / {target_H:.1f}% ìœ ì‚¬ì¼ ë¹„êµ ({metric})"
    if merged.empty:
        st.info("ìœ ì‚¬ì¼ì˜ AHU ì§€í‘œê°€ ì—†ì–´ í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        fig = px.line(
            merged, x="ì—°ë„", y=metric, markers=True,
            title=title, text="ì—°ë„"
        )
        fig.update_traces(textposition="top center")
        fig.update_layout(xaxis=dict(dtick=1))
        st.plotly_chart(fig, use_container_width=True)

        # ë³´ì¡°: ì‹¤ì œ ë§¤ì¹­ëœ ë‚ ì§œ/ì™¸ê¸°/ê±°ë¦¬ í‘œ
        show = merged.copy()
        show["ë‚ ì§œ"] = show["ë‚ ì§œ"].dt.strftime("%Y-%m-%d")
        if metric.endswith("(ì›)"):
            show[metric] = show[metric].apply(lambda x: f"{int(round(x)):,}")
        else:
            show[metric] = show[metric].apply(lambda x: f"{x:,.1f}")
        show["dist"] = show["dist"].apply(lambda x: f"{x:.2f}")
        st.markdown("#### ë§¤ì¹­ ê²°ê³¼í‘œ")
        st.dataframe(
            show[["ì—°ë„","ë‚ ì§œ","ì™¸ê¸°ì˜¨ë„","ì™¸ê¸°ìŠµë„","dist","ì„ ì •ë°©ì‹",metric]],
            use_container_width=True
        )

        st.caption("â€» ë™ì¼ ì™¸ê¸°ì¡°ê±´ì´ ì—†ìœ¼ë©´ ê±°ë¦¬(ì˜¨ë„Â·ìŠµë„ ì°¨)ë¡œ ê°€ì¥ ê°€ê¹Œìš´ ë‚ ì§œë¥¼ ì„ íƒí•©ë‹ˆë‹¤. â€˜í—ˆìš© ì˜¤ì°¨ ë‚´ í‰ê· â€™ì„ ì„ íƒí•˜ë©´ ë²”ìœ„ ë‚´ ì—¬ëŸ¬ ë‚ ì§œì˜ í‰ê· ê°’ìœ¼ë¡œ ë¹„êµí•©ë‹ˆë‹¤.")

    # 1) í•­ëª©ë³„ ì´ ë¹„ìš© ì‚°ì¶œ (CCV, PC_CCV, HCV, DH_HCV)
    í•­ëª©ë¦¬ìŠ¤íŠ¸ = ["CCV", "PC_CCV", "HCV", "DH_HCV"]

    # 2) ì¼ì ë‹¨ìœ„ ë¹„ìš© íŠ¸ë Œë“œ (ë‹¨ìˆœ ì„  ê·¸ë˜í”„)
    cols = [c for c in df_ahu_final.columns if any(c.endswith(f"_{h}") for h in í•­ëª©ë¦¬ìŠ¤íŠ¸)]

    if cols:
        daily_cost = (
            df_ahu_final.groupby(df_ahu_final["datetime"].dt.date)[cols].sum().reset_index()
            .melt(id_vars="datetime", var_name="í•­ëª©", value_name="ê°’")
        )
        daily_cost["í•­ëª©ëª…"] = daily_cost["í•­ëª©"].str.split("_").str[-1]
        daily_cost["ì§€í‘œ"] = daily_cost["í•­ëª©"].str.split("_").str[0]  # kWh or ë¹„ìš©(ì›)
        daily_cost = daily_cost.pivot_table(
            index=["datetime","í•­ëª©ëª…"], columns="ì§€í‘œ", values="ê°’", aggfunc="sum"
        ).reset_index().rename(columns={"datetime":"ë‚ ì§œ"})
    else:
        # ì»¬ëŸ¼ì´ í•˜ë‚˜ë„ ì—†ìœ¼ë©´ ë¹ˆ DataFrame ë¦¬í„´
        daily_cost = pd.DataFrame(columns=["ë‚ ì§œ","í•­ëª©ëª…","kWh","ë¹„ìš©(ì›)"])

    if daily_cost.empty:
        st.info("ğŸ“… ì„ íƒ ê¸°ê°„ì— ì¼ë³„ ë¹„ìš© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        # ì´ì „ì— ë°œìƒí–ˆë˜ ì˜¤ë¥˜ ìˆ˜ì •
        if 'ë‚ ì§œ' not in daily_cost.columns:
            daily_cost = daily_cost.rename(columns={daily_cost.columns[0]: 'ë‚ ì§œ'})
            
        fig = px.line(
            daily_cost,
            x="ë‚ ì§œ", y="ë¹„ìš©(ì›)", color="í•­ëª©ëª…",
            title=f"{ahu} ì¼ë³„ ë¹„ìš© ì¶”ì´",
            markers=True
        )
        st.plotly_chart(fig, use_container_width=True)

    # 3) pivot ê¸°ë°˜ ì¼ìë³„ ë¹„ìš© ì§‘ê³„ (ì´ë¹„ìš© í¬í•¨)
    cols = [f"ë¹„ìš©(ì›)_{h}" for h in ["CCV","PC_CCV","HCV","DH_HCV"] if f"ë¹„ìš©(ì›)_{h}" in df_ahu_final.columns]

    if cols:
        daily_total = (
            df_ahu_final.groupby(df_ahu_final["datetime"].dt.date)[cols].sum().reset_index()
            .melt(id_vars="datetime", var_name="í•­ëª©", value_name="ë¹„ìš©(ì›)")
        )
        daily_total["í•­ëª©ëª…"] = daily_total["í•­ëª©"].str.replace("ë¹„ìš©\\(ì›\\)_","",regex=True)
        daily_total.rename(columns={"datetime":"ë‚ ì§œ"}, inplace=True)
    else:
        daily_total = pd.DataFrame(columns=["ë‚ ì§œ","í•­ëª©","í•­ëª©ëª…","ë¹„ìš©(ì›)"])

    í•­ëª©ë³„_ì¼ì¼ë¹„ìš©_ê·¸ë˜í”„ = []
    if not daily_total.empty:
        pivot_daily = daily_total.pivot_table(
            index="ë‚ ì§œ",  # ê³µì¡°ê¸°ë³„ì´ë©´ ìœ„ì—ì„œ ì»¬ëŸ¼ ì¶”ê°€ í•„ìš”
            columns="í•­ëª©ëª…",
            values="ë¹„ìš©(ì›)",
            aggfunc="sum",
            fill_value=0
        ).reset_index()

        # âœ… ì´ë¹„ìš© ê³„ì‚°
        pivot_daily["ì´ë¹„ìš©(ì›)"] = (
            pivot_daily.get("CCV",0)
            + pivot_daily.get("PC_CCV",0)
            + pivot_daily.get("HCV",0)
            + pivot_daily.get("DH_HCV",0)
        )

        # âœ… tidy í˜•íƒœ ë³€í™˜
        for í•­ëª© in ["CCV","PC_CCV","HCV","DH_HCV","ì´ë¹„ìš©(ì›)"]:
            if í•­ëª© in pivot_daily.columns:
                df_plot = pivot_daily[["ë‚ ì§œ", í•­ëª©]].rename(columns={í•­ëª©:"ë¹„ìš©(ì›)"})
                í•­ëª©ë³„_ì¼ì¼ë¹„ìš©_ê·¸ë˜í”„.append((ahu, í•­ëª©, df_plot))

        # 4) ê³µì¡°ê¸°ë³„ ë¹„ìš© ìš”ì•½í‘œ (ì„ íƒ ê³µì¡°ê¸° 1ëŒ€ ê¸°ì¤€)
        # all_df_range(ê¸°ê°„ í•„í„° ì ìš© ì „ì²´)ì—ì„œ ë™ì¼ ë¡œì§ ì¬ì‚¬ìš©
        summary_raw = make_top_summary(all_df_range, raw=True)

        df_cost = summary_raw[summary_raw["ê³µì¡°ê¸°"] == ì„ íƒê³µì¡°ê¸°].copy()
        if df_cost.empty:
            st.subheader("ğŸ“Š ê³µì¡°ê¸°ë³„ ë¹„ìš© ìš”ì•½í‘œ")
            st.info("ì„ íƒí•œ ê³µì¡°ê¸°ì— ëŒ€í•œ ì§‘ê³„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.subheader("ğŸ“Š ê³µì¡°ê¸°ë³„ ë¹„ìš© ìš”ì•½í‘œ")
            # [ìˆ˜ì •ë¨] Debug print ì œê±° (empty DataFrame ë¡œê·¸ ë°©ì§€)
            df_cost_fmt = df_cost.copy()
            df_cost_fmt.index = np.arange(1, len(df_cost_fmt) + 1)
            df_cost_fmt.index.name = "No"

            money_cols = [c for c in df_cost_fmt.columns if c.endswith("(ì›)")]
            # [ìˆ˜ì •ë¨] applymap deprecation ëŒ€ì‘ (Series.map ì‚¬ìš©)
            df_cost_fmt[money_cols] = df_cost_fmt[money_cols].apply(
                lambda s: s.map(lambda x: f"{int(round(x)):,}" if pd.notna(x) else "")
            )

            ì»¬ëŸ¼_ìƒ‰ìƒë§µ = {
                "ì´ë¹„ìš©(ì›)": "#e6ffe6",
                "ì „ë ¥ì‚¬ìš©ëŸ‰(ì›)": "#fff5e6",
                "ëƒ‰ìˆ˜ì½”ì¼ë¹„ìš©(ì›)": "#e6eeff",
                "ìŠ¤íŒ€ì½”ì¼ë¹„ìš©(ì›)": "#ffe6e6",
            }

            def style_col_background(col):
                color = ì»¬ëŸ¼_ìƒ‰ìƒë§µ.get(col.name, "")
                return [f"background-color: {color}"] * len(col)

            styled = (
                df_cost_fmt.style
                .apply(style_col_background, subset=[c for c in df_cost_fmt.columns if c in ì»¬ëŸ¼_ìƒ‰ìƒë§µ])
            )
            st.dataframe(styled, use_container_width=True)


    # 5) ì¥ì¹˜ë³„ ì „ê¸°ì‚¬ìš©ëŸ‰
    for ahu in [ì„ íƒê³µì¡°ê¸°]:
        # [ìˆ˜ì •ë¨] Empty DataFrame ì²´í¬ ì¶”ê°€
        if not all_df.empty and "ê³µì¡°ê¸°" in all_df.columns and "datetime" in all_df.columns:
            # all_dfë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•„í„°ë§
            df_filt = all_df[
                (all_df["ê³µì¡°ê¸°"] == ahu)
                & (all_df["datetime"] >= ì‹œì‘)
                & (all_df["datetime"] < ì¢…ë£Œ)
            ].copy()
        else:
            df_filt = pd.DataFrame()

        if df_filt.empty:
            continue
            
        rows = []
        ì „ë ¥_cols = [
            c for c in df_filt.columns
            if c.startswith("kWh_")
            and c.split("_", 1)[1] not in ("ëƒ‰ìˆ˜", "ìŠ¤íŒ€")   # kWh_ëƒ‰ìˆ˜ / kWh_ìŠ¤íŒ€ ì œì™¸
        ]

        rows = []
        for col in ì „ë ¥_cols:
            ì¥ì¹˜ = col.split("_", 1)[1]  # ì˜ˆ: "kWh_SFST1" -> "SFST1"
            kwh = df_filt[col].sum()

            h_col = f"ìš´ì „ì‹œê°„(h)_{ì¥ì¹˜}"     # í”¼ë²— ê²°ê³¼ëŠ” 'ìš´ì „ì‹œê°„(h)_SFST1' í˜•íƒœ
            hours = df_filt[h_col].sum() if h_col in df_filt.columns else 0.0

            cost_col = f"ë¹„ìš©(ì›)_{ì¥ì¹˜}"      # 'ë¹„ìš©(ì›)_SFST1'
            cost = df_filt[cost_col].sum() if cost_col in df_filt.columns else None

            if kwh > 0:
                rows.append({
                    "ì¥ì¹˜": ì¥ì¹˜,
                    "ê°€ë™ì‹œê°„(h)": round(hours, 1),
                    "ì‚¬ìš©ëŸ‰(kWh)": int(round(kwh)),
                    "ë¹„ìš©(ì›)": int(round(cost)) if cost is not None else None
                })

        if not rows:
            continue

        df_ì¥ì¹˜ = pd.DataFrame(rows)
        ì¥ì¹˜_ì´ë¦„_í•œê¸€ = {
            "SF": "ì„œí”Œë¼ì´íŒ¬", "AC_SFST": "ì„œí”Œë¼ì´íŒ¬",
            "PC_SFSS": "í”„ë¡œì„¸ìŠ¤íŒ¬", "OAU_SFST": "í”„ë¡œì„¸ìŠ¤íŒ¬", "RFST": "í”„ë¡œì„¸ìŠ¤íŒ¬", "PC_SFST": "í”„ë¡œì„¸ìŠ¤íŒ¬",
            "EFSS": "ë°°ê¸°íŒ¬", "EFST": "ë°°ê¸°íŒ¬", "AC_RFSS": "ë°°ê¸°íŒ¬",
            "CDU": "CDU", "CDUSS": "CDU", "COMP": "CDU",
            "EH": "íˆí„°", "HT": "íˆí„°", "EHSS1": "íˆí„°1", "EHSS2": "íˆí„°2", "EHSS3": "íˆí„°3"
        }
        df_ì¥ì¹˜["ì¥ì¹˜"] = df_ì¥ì¹˜["ì¥ì¹˜"].map(ì¥ì¹˜_ì´ë¦„_í•œê¸€).fillna(df_ì¥ì¹˜["ì¥ì¹˜"])
        df_ì¥ì¹˜["ê°€ë™ì‹œê°„(h)"] = df_ì¥ì¹˜["ê°€ë™ì‹œê°„(h)"].map(lambda x: f"{x:.1f}")
        df_ì¥ì¹˜["ì‚¬ìš©ëŸ‰(kWh)"] = df_ì¥ì¹˜["ì‚¬ìš©ëŸ‰(kWh)"].map(lambda x: f"{x:,}")
        df_ì¥ì¹˜["ë¹„ìš©(ì›)"] = df_ì¥ì¹˜["ë¹„ìš©(ì›)"].map(lambda x: f"{x:,}")

        df_ì¥ì¹˜.index = df_ì¥ì¹˜.index + 1
        df_ì¥ì¹˜.index.name = "No"

        st.markdown(f"#### {ahu} ì¥ì¹˜ë³„ ì „ê¸°ì‚¬ìš©ëŸ‰ ë° ì „ê¸°ë¹„ìš©")
        st.dataframe(df_ì¥ì¹˜, use_container_width=True)
        st.markdown("---")

    # 6) í•­ëª©ë³„/ì´ë¹„ìš© ê·¸ë˜í”„ ì¶œë ¥
    for ahu, í•­ëª©ëª…, ì¼ë³„ in í•­ëª©ë³„_ì¼ì¼ë¹„ìš©_ê·¸ë˜í”„:
        ì¼ë³„ = ì¼ë³„.copy()

         # âœ… ê³µì¡°ê¸° ì»¬ëŸ¼ ë³´ê°•
        ì¼ë³„["ê³µì¡°ê¸°"] = ahu

        # âœ… ë‚ ì§œ ì»¬ëŸ¼ ì•ˆì „ ì²˜ë¦¬
        if "datetime" in ì¼ë³„.columns:
            ì¼ë³„["ë‚ ì§œ"] = pd.to_datetime(ì¼ë³„["datetime"])
        elif "ë‚ ì§œ" in ì¼ë³„.columns:
            ì¼ë³„["ë‚ ì§œ"] = pd.to_datetime(ì¼ë³„["ë‚ ì§œ"])
        else:
            raise KeyError("ì¼ë³„ ë°ì´í„°ì— ë‚ ì§œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")

        ì¼ë³„["ë¹„ìš©(ë§Œì›)"] = ì¼ë³„["ë¹„ìš©(ì›)"] / 10000
        ì¼ë³„["ì—°ë„"] = ì¼ë³„["ë‚ ì§œ"].dt.year
        ì¼ë³„["ì ˆê¸°"] = ì¼ë³„["ë‚ ì§œ"].apply(ì ˆê¸°_ë¶„ë¥˜)

        label = "ì´ë¹„ìš©" if "ì´ë¹„ìš©" in í•­ëª©ëª… else í•­ëª©ëª…_í•œê¸€.get(í•­ëª©ëª…, í•­ëª©ëª…)
        expander_title = f"{label} - {ahu} | ì ˆê¸°ë³„ ì—°ë„ë³„ ì¼ì¼ ë¹„ìš©"

        with st.expander(f"ğŸ“ˆ {expander_title}", expanded=("ì´ë¹„ìš©" in label)):
            draw_season_year_line(
                ì¼ë³„,
                y_col="ë¹„ìš©(ë§Œì›)",
                title=expander_title,
                í‰ê· ì„ _ì»¬ëŸ¼="ë¹„ìš©(ë§Œì›)"
            )
with íƒ­3:
    st.subheader("ğŸ”‹ ê³µì¡°ê¸°ë³„ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ìƒì„¸ ë¶„ì„")

    st.caption("â€» ìƒë‹¨ì—ì„œ ì„¤ì •í•œ ë‚ ì§œ ë²”ìœ„(ğŸ“… ë¶„ì„í•  ë‚ ì§œ ë²”ìœ„ ì„ íƒ)ì— ë§ì¶° ê³µì¡°ê¸°ë³„ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ì„ ì§‘ê³„í•©ë‹ˆë‹¤.")

    # ê¸°ê°„ í•„í„° ì ìš©ëœ ì „ì²´ DF ì‚¬ìš©
    df_energy_base = all_df_range.copy()

    if df_energy_base.empty:
        st.warning("ì„ íƒí•œ ê¸°ê°„ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    # í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ë”ë¼ë„ ì—ëŸ¬ ë‚˜ì§€ ì•Šë„ë¡ ë°©ì–´ì ìœ¼ë¡œ 0 ì»¬ëŸ¼ ìƒì„±
    for col in ["kWh_HCV", "kWh_DH_HCV", "kWh_CCV", "kWh_PC_CCV"]:
        if col not in df_energy_base.columns:
            df_energy_base[col] = 0.0

    # ì „ê¸° ì‚¬ìš©ëŸ‰(kWh) ì»¬ëŸ¼ ì°¾ê¸°: kWh_ì ‘ë‘ì‚¬ / _kWh ì ‘ë¯¸ì‚¬ ì¤‘ì—ì„œ ëƒ‰ìˆ˜/ìŠ¤íŒ€/ì½”ì¼ ê³„ì—´ ì œì™¸
    power_kwh_cols = [c for c in df_energy_base.columns if _is_power_kwh(c)]

    if power_kwh_cols:
        df_energy_base[power_kwh_cols] = df_energy_base[power_kwh_cols].apply(
            pd.to_numeric, errors="coerce"
        ).fillna(0)
    else:
        # ì¥ì¹˜ë³„ kWh ì»¬ëŸ¼ì´ í•˜ë‚˜ë„ ì—†ë‹¤ë©´ ì „ê¸° ì‚¬ìš©ëŸ‰ì€ 0ìœ¼ë¡œ ì²˜ë¦¬
        df_energy_base["ì „ê¸°_ê°€ìƒkWh"] = 0.0
        power_kwh_cols = ["ì „ê¸°_ê°€ìƒkWh"]

    # ì½”ì¼ kWh ìˆ«ìí™”
    kwh_cols_all = ["kWh_HCV", "kWh_DH_HCV", "kWh_CCV", "kWh_PC_CCV"]
    df_energy_base[kwh_cols_all] = df_energy_base[kwh_cols_all].apply(
        pd.to_numeric, errors="coerce"
    ).fillna(0)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 1) ê³µì¡°ê¸°ë³„ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ì§‘ê³„ (kWh)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    grp = df_energy_base.groupby("ê³µì¡°ê¸°", as_index=False).agg(
        ìŠ¤íŒ€_kWh=("kWh_HCV", "sum"),
        ì œìŠµìš©_ìŠ¤íŒ€_kWh=("kWh_DH_HCV", "sum"),
        ëƒ‰ìˆ˜_kWh=("kWh_CCV", "sum"),
        í”„ë¦¬ì¿¨ëŸ¬_ëƒ‰ìˆ˜_kWh=("kWh_PC_CCV", "sum"),
    )

    # ì „ê¸° ì‚¬ìš©ëŸ‰ kWh = power_kwh_cols í•©
    df_power = (
        df_energy_base[["ê³µì¡°ê¸°"] + power_kwh_cols]
        .groupby("ê³µì¡°ê¸°", as_index=False)[power_kwh_cols]
        .sum()
    )
    df_power["ì „ê¸°_kWh"] = df_power[power_kwh_cols].sum(axis=1)

    # ë³‘í•©
    grp = grp.merge(df_power[["ê³µì¡°ê¸°", "ì „ê¸°_kWh"]], on="ê³µì¡°ê¸°", how="left")

    # ì´ ì—ë„ˆì§€(ë¹„êµìš©)
    grp["ì´_kWh"] = (
        grp["ìŠ¤íŒ€_kWh"]
        + grp["ì œìŠµìš©_ìŠ¤íŒ€_kWh"]
        + grp["ëƒ‰ìˆ˜_kWh"]
        + grp["í”„ë¦¬ì¿¨ëŸ¬_ëƒ‰ìˆ˜_kWh"]
        + grp["ì „ê¸°_kWh"]
    )

    # [ìˆ˜ì •ë¨] ë¹„ìœ¨(%) ê³„ì‚°ì€ ìˆ«ì ì»¬ëŸ¼ ìƒíƒœì—ì„œ ë¨¼ì € ìˆ˜í–‰
    df_display = grp.copy()
    for col in ["ìŠ¤íŒ€_kWh", "ì œìŠµìš©_ìŠ¤íŒ€_kWh", "ëƒ‰ìˆ˜_kWh", "í”„ë¦¬ì¿¨ëŸ¬_ëƒ‰ìˆ˜_kWh", "ì „ê¸°_kWh"]:
        ratio_col = col.replace("_kWh", "_ë¹„ì¤‘(%)")
        df_display[ratio_col] = np.where(
            df_display["ì´_kWh"] > 0,
            df_display[col] / df_display["ì´_kWh"] * 100,
            0,
        ).round(1)

    # í‘œì‹œìš© í¬ë§· (ì²œ ë‹¨ìœ„ ì½¤ë§ˆ & ì›ë³¸ ë³´ì¡´)
    for col in ["ìŠ¤íŒ€_kWh", "ì œìŠµìš©_ìŠ¤íŒ€_kWh", "ëƒ‰ìˆ˜_kWh", "í”„ë¦¬ì¿¨ëŸ¬_ëƒ‰ìˆ˜_kWh", "ì „ê¸°_kWh", "ì´_kWh"]:
        df_display[col + "_raw"] = df_display[col]  # ì›ë³¸ ê°’ ë³´ì¡´
        df_display[col] = df_display[col].apply(lambda x: f"{x:,.1f}")

    # í‘œì‹œìš© ì»¬ëŸ¼ë§Œ ì„ íƒ
    cols_order = [
        "ê³µì¡°ê¸°",
        "ìŠ¤íŒ€_kWh", "ìŠ¤íŒ€_ë¹„ì¤‘(%)",
        "ì œìŠµìš©_ìŠ¤íŒ€_kWh", "ì œìŠµìš©_ìŠ¤íŒ€_ë¹„ì¤‘(%)",
        "ëƒ‰ìˆ˜_kWh", "ëƒ‰ìˆ˜_ë¹„ì¤‘(%)",
        "í”„ë¦¬ì¿¨ëŸ¬_ëƒ‰ìˆ˜_kWh", "í”„ë¦¬ì¿¨ëŸ¬_ëƒ‰ìˆ˜_ë¹„ì¤‘(%)",
        "ì „ê¸°_kWh", "ì „ê¸°_ë¹„ì¤‘(%)",
        "ì´_kWh",
    ]
    # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì‚¬ìš©
    cols_order = [c for c in cols_order if c in df_display.columns]

    st.markdown("### ğŸ“˜ ê³µì¡°ê¸°ë³„ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ìš”ì•½ (kWh ê¸°ì¤€)")
    df_display_show = df_display[cols_order].copy()
    df_display_show.index = range(1, len(df_display_show) + 1)
    df_display_show.index.name = "No"
    st.dataframe(df_display_show, use_container_width=True)

    st.caption("â€» kWh ê¸°ì¤€ìœ¼ë¡œ ìŠ¤íŒ€/ì œìŠµ ìŠ¤íŒ€/ëƒ‰ìˆ˜/í”„ë¦¬ì¿¨ëŸ¬ ëƒ‰ìˆ˜/ì „ê¸° ì‚¬ìš©ëŸ‰ê³¼ ê° ë¹„ì¤‘(%)ì„ í‘œì‹œí•©ë‹ˆë‹¤.")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 2) ê³µì¡°ê¸°ë³„ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ë¹„êµ (ë§‰ëŒ€ ê·¸ë˜í”„)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # tidy í˜•íƒœë¡œ melt
    melt_cols = ["ìŠ¤íŒ€_kWh", "ì œìŠµìš©_ìŠ¤íŒ€_kWh", "ëƒ‰ìˆ˜_kWh", "í”„ë¦¬ì¿¨ëŸ¬_ëƒ‰ìˆ˜_kWh", "ì „ê¸°_kWh"]
    melt_cols = [c for c in melt_cols if c in grp.columns]

    df_bar = grp[["ê³µì¡°ê¸°"] + melt_cols].copy()
    df_bar_melt = df_bar.melt(id_vars="ê³µì¡°ê¸°", var_name="ì—ë„ˆì§€ì¢…ë¥˜", value_name="kWh")
    df_bar_melt["kWh"] = df_bar_melt["kWh"].fillna(0)

    st.markdown("### ğŸ“Š ê³µì¡°ê¸°ë³„ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ë¹„êµ")

    fig_bar = px.bar(
        df_bar_melt,
        x="ê³µì¡°ê¸°",
        y="kWh",
        color="ì—ë„ˆì§€ì¢…ë¥˜",
        barmode="stack",
        title="ê³µì¡°ê¸°ë³„ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰(ìŠ¤íƒí˜•, kWh)",
    )
    fig_bar.update_layout(xaxis_title="ê³µì¡°ê¸°", yaxis_title="ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ (kWh)")
    st.plotly_chart(fig_bar, use_container_width=True)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 3) íŠ¹ì • ê³µì¡°ê¸° ì„ íƒ í›„ ì¼ë³„ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ì¶”ì´
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.markdown("### ğŸ“ˆ ì„ íƒ ê³µì¡°ê¸° ì¼ë³„ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ì¶”ì´")

    ì„ íƒê³µì¡°ê¸°_ì—ë„ˆì§€ = st.selectbox(
        "ìƒì„¸ ë¶„ì„í•  ê³µì¡°ê¸°ë¥¼ ì„ íƒí•˜ì„¸ìš”",
        sorted(grp["ê³µì¡°ê¸°"].unique()),
        key="ì„ íƒê³µì¡°ê¸°_ì—ë„ˆì§€_íƒ­3",
    )

    df_ahu_energy = df_energy_base[df_energy_base["ê³µì¡°ê¸°"] == ì„ íƒê³µì¡°ê¸°_ì—ë„ˆì§€].copy()
    if df_ahu_energy.empty:
        st.info("ì„ íƒí•œ ê³µì¡°ê¸°ì˜ í•´ë‹¹ ê¸°ê°„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        df_ahu_energy["ë‚ ì§œ"] = df_ahu_energy["datetime"].dt.normalize()

        # ì¼ë³„ í•©ì‚°
        daily_ahu = df_ahu_energy.groupby("ë‚ ì§œ", as_index=False).agg(
            ìŠ¤íŒ€_kWh=("kWh_HCV", "sum"),
            ì œìŠµìš©_ìŠ¤íŒ€_kWh=("kWh_DH_HCV", "sum"),
            ëƒ‰ìˆ˜_kWh=("kWh_CCV", "sum"),
            í”„ë¦¬ì¿¨ëŸ¬_ëƒ‰ìˆ˜_kWh=("kWh_PC_CCV", "sum"),
        )

        df_power_daily = (
            df_ahu_energy[["ë‚ ì§œ"] + power_kwh_cols]
            .groupby("ë‚ ì§œ", as_index=False)[power_kwh_cols]
            .sum()
        )
        df_power_daily["ì „ê¸°_kWh"] = df_power_daily[power_kwh_cols].sum(axis=1)

        daily_ahu = daily_ahu.merge(df_power_daily[["ë‚ ì§œ", "ì „ê¸°_kWh"]], on="ë‚ ì§œ", how="left")
        daily_ahu = daily_ahu.fillna(0)

        # tidy í˜•íƒœë¡œ melt
        melt_cols_daily = ["ìŠ¤íŒ€_kWh", "ì œìŠµìš©_ìŠ¤íŒ€_kWh", "ëƒ‰ìˆ˜_kWh", "í”„ë¦¬ì¿¨ëŸ¬_ëƒ‰ìˆ˜_kWh", "ì „ê¸°_kWh"]
        df_daily_melt = daily_ahu.melt(id_vars="ë‚ ì§œ", var_name="ì—ë„ˆì§€ì¢…ë¥˜", value_name="kWh")
        df_daily_melt["kWh"] = df_daily_melt["kWh"].fillna(0)

        fig_line = px.line(
            df_daily_melt,
            x="ë‚ ì§œ",
            y="kWh",
            color="ì—ë„ˆì§€ì¢…ë¥˜",
            markers=True,
            title=f"{ì„ íƒê³µì¡°ê¸°_ì—ë„ˆì§€} ì¼ë³„ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ì¶”ì´ (kWh)",
        )
        fig_line.update_layout(xaxis_title="ë‚ ì§œ", yaxis_title="ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ (kWh)")
        st.plotly_chart(fig_line, use_container_width=True)

        with st.expander("ğŸ“„ ì„ íƒ ê³µì¡°ê¸° ì¼ë³„ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ í‘œ ë³´ê¸°", expanded=False):
            df_daily_show = daily_ahu.copy()
            for col in ["ìŠ¤íŒ€_kWh", "ì œìŠµìš©_ìŠ¤íŒ€_kWh", "ëƒ‰ìˆ˜_kWh", "í”„ë¦¬ì¿¨ëŸ¬_ëƒ‰ìˆ˜_kWh", "ì „ê¸°_kWh"]:
                if col in df_daily_show.columns:
                    df_daily_show[col] = df_daily_show[col].apply(lambda x: f"{x:,.1f}")
            st.dataframe(df_daily_show, use_container_width=True)






with íƒ­5:
    st.subheader("ğŸ“Š í•­ëª©ë³„ ìš”ì•½ í†µê³„")

    # === ìƒ‰ìƒ & í•­ëª©ëª… ë§¤í•‘ ===
    í•­ëª©_ìƒ‰ìƒë§µ = {
        "í”„ë¦¬ì¿¨ëŸ¬ ëƒ‰ìˆ˜ì½”ì¼": "#f0faff",
        "ëƒ‰ìˆ˜ì½”ì¼": "#e6eeff",
        "ì œìŠµ ìŠ¤íŒ€ì½”ì¼": "#f5d9c6",
        "ìŠ¤íŒ€ì½”ì¼": "#ffe6e6",
        "í™˜ê¸°ì˜¨ë„": "#d3ebac",
        "í™˜ê¸°ìŠµë„": "#b9cfca"
    }
    í•­ëª©ëª…_ì •ê·œí™” = {
        "CCV": "ëƒ‰ìˆ˜ì½”ì¼",
        "PC_CCV": "í”„ë¦¬ì¿¨ëŸ¬ ëƒ‰ìˆ˜ì½”ì¼",
        "HCV": "ìŠ¤íŒ€ì½”ì¼",
        "DH_HCV": "ì œìŠµ ìŠ¤íŒ€ì½”ì¼",
        "RAT": "í™˜ê¸°ì˜¨ë„",
        "RAH": "í™˜ê¸°ìŠµë„",
    }

    def style_by_í•­ëª©(row, ref_df):
        color = í•­ëª©_ìƒ‰ìƒë§µ.get(ref_df.loc[row.name, "í•­ëª©_ì •ê·œí™”"], "")
        return [f"background-color: {color}"] * len(row)

    def show_styled_dataframe(df_raw, name="í‘œ", show_index=True):
        ref_df = df_raw.copy()
        df = df_raw.drop(columns=["í•­ëª©_ì •ê·œí™”"])
        styled_df = df.style.apply(style_by_í•­ëª©, axis=1, args=(ref_df,))
        st.markdown(name)
        st.dataframe(styled_df, use_container_width=True, hide_index=not show_index)

    # âœ… final_analysis parquet ê¸°ë°˜ ë°ì´í„°
    items = get_items_from_final(all_df)
    target_items = ["CCV","PC_CCV","HCV","DH_HCV","RAT","RAH"]
    use_items = [i for i in target_items if i in items]

    # ìµœì†Œ 1ê°œ ì´ìƒ ìˆì„ ë•Œë§Œ ì§„í–‰
    cols = []
    for h in use_items:
        for prefix in ["kWh","ë¹„ìš©(ì›)","í‰ê·  ê°œë„ìœ¨(%)"]:
            col = f"{prefix}_{h}"
            if col in all_df.columns:
                cols.append(col)

    if not cols:
        st.info("ğŸ“Š ì„ íƒëœ ê¸°ê°„ì— í•´ë‹¹ í•­ëª© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        df_summary = pd.DataFrame(columns=["ì—°ë„","ì ˆê¸°","í•­ëª©ëª…","ëˆ„ì  ì—´ëŸ‰(kWh)","í‰ê· ê°’","í‰ê·  ê°œë„ìœ¨(%)"])
    else:
        # long í˜•íƒœë¡œ ë³€í™˜ (ë”± í•œ ë²ˆë§Œ melt)
        df_energy = all_df[["ê³µì¡°ê¸°","datetime"] + cols].copy()
        df_energy = df_energy.melt(id_vars=["ê³µì¡°ê¸°","datetime"], var_name="ì§€í‘œ", value_name="ê°’")
        df_energy["í•­ëª©ëª…"] = df_energy["ì§€í‘œ"].str.split("_").str[-1]
        df_energy["ì§€í‘œíƒ€ì…"] = df_energy["ì§€í‘œ"].str.split("_").str[0]  # 'kWh' / 'ë¹„ìš©(ì›)' / 'í‰ê·  ê°œë„ìœ¨(%)'
        df_energy["ì—°ë„"] = df_energy["datetime"].dt.year
        df_energy["ì ˆê¸°"] = df_energy["datetime"].apply(ì ˆê¸°_ë¶„ë¥˜)

        # 1) ì½”ì¼ ì—ë„ˆì§€(kWh) ëˆ„ì  (ì—¬ê¸°ì„œ 'kWh' ì»¬ëŸ¼ì´ ì•„ë‹ˆë¼ ê°’ ì»¬ëŸ¼ì„ í•©ì‚°)
        df_energy_kwh = (
            df_energy[
                (df_energy["í•­ëª©ëª…"].isin(["CCV","PC_CCV","HCV","DH_HCV"])) &
                (df_energy["ì§€í‘œíƒ€ì…"] == "kWh")
            ]
            .groupby(["ì—°ë„","ì ˆê¸°","í•­ëª©ëª…"], as_index=False)["ê°’"]
            .sum()
            .rename(columns={"ê°’": "ëˆ„ì  ì—´ëŸ‰(kWh)"})
        )

        # 2) RAT/RAH í‰ê· 
        df_avg = (
            df_energy[df_energy["í•­ëª©ëª…"].isin(["RAT","RAH"])]
            .groupby(["ì—°ë„","ì ˆê¸°","í•­ëª©ëª…"], as_index=False)["ê°’"]
            .mean()
            .rename(columns={"ê°’": "í‰ê· ê°’"})
        )

        # 3) í†µí•©
        df_summary = pd.concat([df_energy_kwh, df_avg], ignore_index=True)

        # í•­ëª©ëª… í•œê¸€í™”ìš© ì •ê·œí™” & ì •ë ¬
        df_summary["í•­ëª©_ì •ê·œí™”"] = df_summary["í•­ëª©ëª…"].map(í•­ëª©ëª…_ì •ê·œí™”).fillna(df_summary["í•­ëª©ëª…"])
        df_summary = df_summary.sort_values(["ì—°ë„","ì ˆê¸°","í•­ëª©_ì •ê·œí™”"]).reset_index(drop=True)

        # ì¶œë ¥
        show_styled_dataframe(df_summary, name="ğŸ“Š ì—°ë„/ì ˆê¸°ë³„ ìš”ì•½ í†µê³„", show_index=False)

        # ğŸŒ¬ í™˜ê¸°ì˜¨ìŠµë„ ì¶”ê°€ (detail parquet ê¸°ë°˜)
        raw = load_ahu_detail_by_mode(ì„ íƒê³µì¡°ê¸°, mode)
        if raw is not None and not raw.empty:
            df_vent = raw[
                (raw["í•­ëª©ëª…"].isin(["RAT", "RAH"])) &
                (raw["datetime"] >= ì‹œì‘) &
                (raw["datetime"] <  ì¢…ë£Œ)
            ].copy()
            if not df_vent.empty:
                df_vent["ì—°ë„"] = df_vent["datetime"].dt.year
                df_vent["ì ˆê¸°"] = df_vent["datetime"].apply(ì ˆê¸°_ë¶„ë¥˜)
                df_vent_summary = (
                    df_vent.groupby(["ì—°ë„", "ì ˆê¸°", "í•­ëª©ëª…"])["ê°’"]
                    .mean()
                    .reset_index()
                    .rename(columns={"ê°’": "í‰ê· ê°’"})
                )
                df_vent_summary["ëˆ„ì  ì—´ëŸ‰(kWh)"] = None
                df_vent_summary["í‰ê·  ê°œë„ìœ¨(%)"] = None
                df_summary = pd.concat([df_summary, df_vent_summary], ignore_index=True)


        # í•­ëª©ëª… í•œê¸€í™”
        df_summary["í•­ëª©ëª…"] = df_summary["í•­ëª©ëª…"].map(í•­ëª©ëª…_ì •ê·œí™”).fillna(df_summary["í•­ëª©ëª…"])


    # ---- ì›”ë³„ í‰ê·  ê°œë„ìœ¨(%) ê³„ì‚° ----
    coil_items = ["CCV", "PC_CCV", "HCV", "DH_HCV"]

    raw = load_ahu_detail_by_mode(ì„ íƒê³µì¡°ê¸°, mode)

    if raw is not None and not raw.empty:
        # ì½”ì¼ í•­ëª© + ê¸°ê°„ í•„í„°
        df_raw = raw[
            (raw["í•­ëª©ëª…"].isin(coil_items)) &
            (raw["datetime"] >= ì‹œì‘) &
            (raw["datetime"] <  ì¢…ë£Œ)
        ].copy()

        if df_raw.empty:
            ì›”ë³„_í‰ê· ê°œë„ìœ¨ = pd.DataFrame(columns=["ê³µì¡°ê¸°","ì›”","í•­ëª©","í‰ê·  ê°œë„ìœ¨(%)"])
        else:
            # ì‹œê°„ ê°€ì¤‘ì¹˜ ê³„ì‚° (ìƒ˜í”Œ ê°„ê²© ê¸°ë°˜)
            df_raw = df_raw.sort_values(["í•­ëª©ëª…","datetime"])
            df_raw["dt_h"] = (
                df_raw.groupby("í•­ëª©ëª…")["datetime"]
                    .diff()
                    .dt.total_seconds()
                    .div(3600)
            )

            # ì²« ìƒ˜í”Œ/ë¹„ì •ìƒ ê°„ê²© ì œê±° (0 < dt <= 12hë§Œ ì¸ì •)
            df_raw = df_raw[(df_raw["dt_h"] > 0) & (df_raw["dt_h"] <= 12)].copy()
            df_raw["ì›”"] = df_raw["datetime"].dt.to_period("M")

            # ì‹œê°„ê°€ì¤‘ í‰ê·  ê°œë„ìœ¨(%)
            def _wavg(g):
                return np.average(g["ê°’"], weights=g["dt_h"])

            wavg = (
                df_raw.groupby(["ì›”","í•­ëª©ëª…"])
                    .apply(_wavg)
                    .reset_index(name="í‰ê·  ê°œë„ìœ¨(%)")
            )

            # í‘œ ì •ë¦¬
            wavg["ê³µì¡°ê¸°"] = ì„ íƒê³µì¡°ê¸°
            wavg["ì›”"] = wavg["ì›”"].astype(str)
            wavg["í•­ëª©"] = wavg["í•­ëª©ëª…"].map(í•­ëª©ëª…_í•œê¸€).fillna(wavg["í•­ëª©ëª…"])
            ì›”ë³„_í‰ê· ê°œë„ìœ¨ = wavg[["ê³µì¡°ê¸°","ì›”","í•­ëª©","í‰ê·  ê°œë„ìœ¨(%)"]]

    else:
        ì›”ë³„_í‰ê· ê°œë„ìœ¨ = pd.DataFrame(columns=["ê³µì¡°ê¸°","ì›”","í•­ëª©","í‰ê·  ê°œë„ìœ¨(%)"])

    # ğŸ‘‰ í™”ë©´ì— í‘œì‹œ
    st.subheader("ğŸ“Œ ì›”ë³„ í‰ê·  ê°œë„ìœ¨(%)")
    st.dataframe(ì›”ë³„_í‰ê· ê°œë„ìœ¨, use_container_width=True)


    if not ì›”ë³„_í‰ê· ê°œë„ìœ¨.empty:
        ì—°ë„ë³„_í‰ê· ê°œë„ìœ¨ = (
            ì›”ë³„_í‰ê· ê°œë„ìœ¨
            .assign(ì—°ë„=lambda x: x["ì›”"].str[:4].astype(int))  # ğŸ”¹ ì—¬ê¸°ì„œ ë°”ë¡œ intë¡œ
            .groupby(["í•­ëª©","ì—°ë„"], as_index=False)["í‰ê·  ê°œë„ìœ¨(%)"]
            .mean()
        )
    else:
        ì—°ë„ë³„_í‰ê· ê°œë„ìœ¨ = pd.DataFrame(columns=["í•­ëª©","ì—°ë„","í‰ê·  ê°œë„ìœ¨(%)"])

    # ì—°ë„ë³„ ì‹¤ì œ ë‚ ì§œ ìˆ˜
    ì¼ìˆ˜_df = (
        df_energy.groupby(df_energy["datetime"].dt.year)
        .agg(ì¼ìˆ˜=("datetime", "nunique"))
        .reset_index()
        .rename(columns={"datetime": "ì—°ë„"})
    )

    # df_summaryì—ëŠ” 'í‰ê·  ê°œë„ìœ¨(%)' ì•„ì§ ì—†ìŒ â†’ agg ëŒ€ìƒì—ì„œ ì œì™¸
    df_ì—°ë„ë³„ = (
        df_summary.groupby(["í•­ëª©ëª…", "ì—°ë„"], as_index=False)
        .agg({
            "ëˆ„ì  ì—´ëŸ‰(kWh)": "sum",
            "í‰ê· ê°’": "mean"
        })
        .merge(ì¼ìˆ˜_df, on="ì—°ë„", how="left")
    )

    df_ì—°ë„ë³„ = df_ì—°ë„ë³„.rename(columns={"í•­ëª©ëª…": "í•­ëª©"})

    # í‰ê·  ì—´ëŸ‰(kWh) ê³„ì‚°
    df_ì—°ë„ë³„["í‰ê·  ì—´ëŸ‰(kWh)"] = df_ì—°ë„ë³„["ëˆ„ì  ì—´ëŸ‰(kWh)"] / df_ì—°ë„ë³„["ì¼ìˆ˜"]



    df_ì—°ë„ë³„ = df_ì—°ë„ë³„.rename(columns={"í•­ëª©ëª…": "í•­ëª©", "ë‚ ì§œ": "ì¼ìˆ˜"})

    # í‰ê·  ì—´ëŸ‰ = ëˆ„ì  ì—´ëŸ‰ Ã· ì‹¤ì œ ì¼ìˆ˜
    df_ì—°ë„ë³„["í‰ê·  ì—´ëŸ‰(kWh)"] = df_ì—°ë„ë³„["ëˆ„ì  ì—´ëŸ‰(kWh)"] / df_ì—°ë„ë³„["ì¼ìˆ˜"]

    # ì—ë„ˆì§€ í•­ëª©ë§Œ (ì½”ì¼)
    df_energy_only = df_ì—°ë„ë³„[~df_ì—°ë„ë³„["í•­ëª©"].isin(["í™˜ê¸°ì˜¨ë„", "í™˜ê¸°ìŠµë„"])].copy()
    df_energy_only = df_energy_only[["í•­ëª©","ì—°ë„","ëˆ„ì  ì—´ëŸ‰(kWh)","í‰ê·  ì—´ëŸ‰(kWh)"]]  # âœ… ì—¬ê¸°ì„œ 'í‰ê·  ê°œë„ìœ¨(%)' ì œê±°

    df_energy_only = df_energy_only.merge(ì—°ë„ë³„_í‰ê· ê°œë„ìœ¨, on=["í•­ëª©","ì—°ë„"], how="left")
    # ìˆ«ì í¬ë§·íŒ…
    df_energy_only["ëˆ„ì  ì—´ëŸ‰(kWh)"] = df_energy_only["ëˆ„ì  ì—´ëŸ‰(kWh)"].apply(lambda x: f"{int(round(x)):,}")
    df_energy_only["í‰ê·  ì—´ëŸ‰(kWh)"] = df_energy_only["í‰ê·  ì—´ëŸ‰(kWh)"].apply(lambda x: f"{int(round(x)):,}")
    df_energy_only["í‰ê·  ê°œë„ìœ¨(%)"] = df_energy_only["í‰ê·  ê°œë„ìœ¨(%)"].apply(lambda x: f"{x:.2f}" if pd.notna(x) else "")
    df_energy_only["í•­ëª©_ì •ê·œí™”"] = df_energy_only["í•­ëª©"].map(í•­ëª©ëª…_ì •ê·œí™”).fillna(df_energy_only["í•­ëª©"])
    df_energy_only.index = range(1, len(df_energy_only) + 1)
    df_energy_only.index.name = "No"
    show_styled_dataframe(df_energy_only, "ğŸ“Œ **í•­ëª©ë³„ ì—°ë„ë³„ ì—´ëŸ‰ ë° í‰ê·  ê°œë„ìœ¨**")

    # ğŸ”¹ í™˜ê²½ í•­ëª©ë§Œ (RAT, RAH)
    df_env = df_ì—°ë„ë³„[df_ì—°ë„ë³„["í•­ëª©"].isin(["í™˜ê¸°ì˜¨ë„", "í™˜ê¸°ìŠµë„"])].copy()
    df_env = df_env[["í•­ëª©","ì—°ë„","í‰ê· ê°’"]]
    df_env["í‰ê· ê°’"] = df_env.apply(
        lambda row: f"{row['í‰ê· ê°’']:.2f} â„ƒ" if row["í•­ëª©"] == "í™˜ê¸°ì˜¨ë„" else f"{row['í‰ê· ê°’']:.2f} %", axis=1
    )
    df_env["í•­ëª©_ì •ê·œí™”"] = df_env["í•­ëª©"].map(í•­ëª©ëª…_ì •ê·œí™”).fillna(df_env["í•­ëª©"])
    df_env["í•­ëª©"] = pd.Categorical(df_env["í•­ëª©"], categories=["í™˜ê¸°ì˜¨ë„", "í™˜ê¸°ìŠµë„"], ordered=True)
    df_env = df_env.sort_values(["í•­ëª©","ì—°ë„"]).reset_index(drop=True)
    df_env.index = range(1, len(df_env) + 1)
    df_env.index.name = "No"
    show_styled_dataframe(df_env, "ğŸŒ¡ï¸ğŸ’§ **ì—°ë„ë³„ í™˜ê¸°ì˜¨ìŠµë„ ìš”ì•½**")


    # âœ… ì ˆê¸°ë³„ ìš”ì•½
    df_coil = df_summary[~df_summary["í•­ëª©ëª…"].isin(["í™˜ê¸°ì˜¨ë„", "í™˜ê¸°ìŠµë„"])].copy()
    df_coil = df_coil.rename(columns={"í•­ëª©ëª…": "í•­ëª©"})

    # ì ˆê¸°ë³„ ì¼ìˆ˜ ê³„ì‚°
    df_days = df_coil.groupby(["ì—°ë„", "ì ˆê¸°"])["í•­ëª©"].count().reset_index(name="ì¼ìˆ˜")

    # merge í•´ì„œ ì ˆê¸°ë³„ ì¼ìˆ˜ ë¶™ì´ê¸°
    df_coil = df_coil.merge(df_days, on=["ì—°ë„", "ì ˆê¸°"], how="left")

    # í‰ê·  ì—´ëŸ‰ì„ ì ˆê¸°ë³„ ì¼ìˆ˜ë¡œ ë‚˜ëˆ”
    df_coil["í‰ê·  ì—´ëŸ‰(kWh)"] = df_coil["ëˆ„ì  ì—´ëŸ‰(kWh)"].astype(float) / df_coil["ì¼ìˆ˜"]

    # í‘œì‹œìš© í¬ë§· ì ìš©
    df_coil["ëˆ„ì  ì—´ëŸ‰(kWh)"] = df_coil["ëˆ„ì  ì—´ëŸ‰(kWh)"].apply(lambda x: f"{x:,.1f}")
    df_coil["í‰ê·  ì—´ëŸ‰(kWh)"] = df_coil["í‰ê·  ì—´ëŸ‰(kWh)"].apply(lambda x: f"{x:,.1f}")

    # í•„ìš”í•œ ì»¬ëŸ¼ ì •ë¦¬
    df_coil = df_coil[["í•­ëª©", "ì—°ë„", "ì ˆê¸°", "ëˆ„ì  ì—´ëŸ‰(kWh)", "í‰ê·  ì—´ëŸ‰(kWh)"]]
    df_coil["í•­ëª©_ì •ê·œí™”"] = df_coil["í•­ëª©"].map(í•­ëª©ëª…_ì •ê·œí™”).fillna(df_coil["í•­ëª©"])
    df_coil = df_coil.sort_values(["í•­ëª©", "ì—°ë„", "ì ˆê¸°"]).reset_index(drop=True)
    df_coil.index = range(1, len(df_coil) + 1)
    df_coil.index.name = "No"
    show_styled_dataframe(df_coil, "ğŸ“Œ **ì ˆê¸°ë³„ í•­ëª©ë³„ ì—´ëŸ‰ ë° í‰ê·  ê°œë„ìœ¨**")

    # âœ… ì ˆê¸°ë³„ í™˜ê¸°ì˜¨ìŠµë„ ìš”ì•½
    df_env_season = df_summary[df_summary["í•­ëª©ëª…"].isin(["í™˜ê¸°ì˜¨ë„", "í™˜ê¸°ìŠµë„"])].copy()
    df_env_season = df_env_season.rename(columns={"í•­ëª©ëª…": "í•­ëª©"})
    df_env_season = df_env_season[["í•­ëª©", "ì—°ë„", "ì ˆê¸°", "í‰ê· ê°’"]].copy()
    df_env_season["í‰ê· ê°’"] = df_env_season.apply(
        lambda row: f"{row['í‰ê· ê°’']:.2f} â„ƒ" if row["í•­ëª©"] == "í™˜ê¸°ì˜¨ë„" else f"{row['í‰ê· ê°’']:.2f} %", axis=1
    )
    df_env_season["í•­ëª©_ì •ê·œí™”"] = df_env_season["í•­ëª©"].map(í•­ëª©ëª…_ì •ê·œí™”).fillna(df_env_season["í•­ëª©"])
    df_env_season["í•­ëª©"] = pd.Categorical(df_env_season["í•­ëª©"], categories=["í™˜ê¸°ì˜¨ë„", "í™˜ê¸°ìŠµë„"], ordered=True)
    df_env_season = df_env_season.sort_values(["í•­ëª©", "ì—°ë„", "ì ˆê¸°"]).reset_index(drop=True)
    df_env_season.index = range(1, len(df_env_season) + 1)
    df_env_season.index.name = "No"
    show_styled_dataframe(df_env_season, "ğŸŒ¡ï¸ğŸ’§ **ì ˆê¸°ë³„ í™˜ê¸°ì˜¨ìŠµë„ ìš”ì•½**")



    # ---- ì›”ë³„ ê°œë„ìœ¨Â·kWhÂ·ë¹„ìš© (parquet + [ì„ íƒ] RAW ê°œë„ìœ¨) ----
    coil_items = ["CCV","PC_CCV","HCV","DH_HCV"]

    # 1) parquet(final_analysis)ì—ì„œ ì›”ë³„ kWh/ë¹„ìš© ì§‘ê³„
    coil_items = ["CCV","PC_CCV","HCV","DH_HCV"]
    cols = []
    for h in coil_items:
        for prefix in ["kWh","ë¹„ìš©(ì›)"]:
            col = f"{prefix}_{h}"
            if col in all_df.columns:
                cols.append(col)

    df_ahu_final = all_df[
        (all_df["ê³µì¡°ê¸°"] == ì„ íƒê³µì¡°ê¸°)
        & (all_df["datetime"] >= ì‹œì‘)
        & (all_df["datetime"] < ì¢…ë£Œ)
    ][["datetime"]+cols].copy()

    df_ahu_final = df_ahu_final.melt(id_vars=["datetime"], var_name="ì§€í‘œ", value_name="ê°’")
    df_ahu_final["í•­ëª©ëª…"] = df_ahu_final["ì§€í‘œ"].str.split("_").str[-1]
    df_ahu_final["ì§€í‘œíƒ€ì…"] = df_ahu_final["ì§€í‘œ"].str.split("_").str[0]  # kWh or ë¹„ìš©(ì›)


    if df_ahu_final.empty:
        ì›”ë³„_ê°œë„ìœ¨_kWh_ë¹„ìš©_í‘œ = pd.DataFrame(columns=["ì›”","í•­ëª©ëª…","kWh","ë¹„ìš©(ì›)","í‰ê·  ê°œë„ìœ¨(%)"])
    else:
        df_ahu_final["ì›”"] = df_ahu_final["datetime"].dt.to_period("M")

        # ì§€í‘œíƒ€ì…(kWh / ë¹„ìš©(ì›))ì„ ì¹¼ëŸ¼ìœ¼ë¡œ í”¼ë²—í•´ì„œ í•©ì‚°
        base_monthly = (
            df_ahu_final
            .pivot_table(
                index=["ì›”","í•­ëª©ëª…"],
                columns="ì§€í‘œíƒ€ì…",      # <- 'kWh', 'ë¹„ìš©(ì›)' ê°’ì´ ë“¤ì–´ìˆìŒ
                values="ê°’",
                aggfunc="sum",
            )
            .reset_index()
        )

        # í”¼ë²— í›„ ì»¬ëŸ¼ì´ ì—†ì„ ìˆ˜ ìˆìœ¼ë‹ˆ ë°©ì–´ì ìœ¼ë¡œ ë³´ì¥
        if "kWh" not in base_monthly.columns:
            base_monthly["kWh"] = np.nan
        if "ë¹„ìš©(ì›)" not in base_monthly.columns:
            base_monthly["ë¹„ìš©(ì›)"] = np.nan


        # 2) [ì„ íƒ] RAW(detail parquet)ì—ì„œ 'í‰ê·  ê°œë„ìœ¨(%)'ë§Œ ê°€ì¤‘í‰ê· ìœ¼ë¡œ ê³„ì‚°í•´ì„œ ë³‘í•©
        raw = load_ahu_detail_by_mode(ì„ íƒê³µì¡°ê¸°, mode)  # detail parquet(ì›ì‹œì‹œê³„ì—´) ìˆìœ¼ë©´ ì‚¬ìš©
        if raw is not None and not raw.empty:
            raw = raw[
                (raw["í•­ëª©ëª…"].isin(coil_items))
                & (raw["datetime"] >= ì‹œì‘)
                & (raw["datetime"] < ì¢…ë£Œ)
            ].copy()
            raw = raw.sort_values("datetime")
            raw["dt_h"] = raw["datetime"].diff().dt.total_seconds()/3600
            raw = raw[(raw["dt_h"] > 0) & (raw["dt_h"] <= 12)].copy()
            if not raw.empty:
                raw["ì›”"] = raw["datetime"].dt.to_period("M")
                # ì‹œê°„ê°€ì¤‘ í‰ê·  ê°œë„ìœ¨
                wavg = (
                    raw.groupby(["ì›”","í•­ëª©ëª…"])
                    .apply(lambda g: np.average(g["ê°’"], weights=g["dt_h"]))
                    .reset_index(name="í‰ê·  ê°œë„ìœ¨(%)")
                )
                ì›”ë³„_ê°œë„ìœ¨_kWh_ë¹„ìš©_í‘œ = base_monthly.merge(wavg, on=["ì›”","í•­ëª©ëª…"], how="left")
            else:
                ì›”ë³„_ê°œë„ìœ¨_kWh_ë¹„ìš©_í‘œ = base_monthly.assign(**{"í‰ê·  ê°œë„ìœ¨(%)": np.nan})
        else:
            ì›”ë³„_ê°œë„ìœ¨_kWh_ë¹„ìš©_í‘œ = base_monthly.assign(**{"í‰ê·  ê°œë„ìœ¨(%)": np.nan})

    # ë³´ê¸° ì¢‹ê²Œ ì›”ì„ ë¬¸ìì—´ë¡œ
    ì›”ë³„_ê°œë„ìœ¨_kWh_ë¹„ìš©_í‘œ["ì›”"] = ì›”ë³„_ê°œë„ìœ¨_kWh_ë¹„ìš©_í‘œ["ì›”"].astype(str)


    # ğŸŸ© ì›”ë³„ í™˜ê¸°ì˜¨ë„/ì™¸ê¸°ì˜¨ë„ í‰ê· 
    raw = load_ahu_detail_by_mode(ì„ íƒê³µì¡°ê¸°, mode)
    if raw is not None and not raw.empty:
        df_rat = raw[raw["í•­ëª©ëª…"] == "RAT"].copy()
        if not df_rat.empty:
            df_rat["ì›”"] = df_rat["datetime"].dt.to_period("M")
            ì›”ë³„_í™˜ê¸°ì˜¨ë„ = df_rat.groupby("ì›”")["ê°’"].mean().reset_index(name="í™˜ê¸°ì˜¨ë„ í‰ê· (Â°C)")
        else:
            ì›”ë³„_í™˜ê¸°ì˜¨ë„ = pd.DataFrame(columns=["ì›”","í™˜ê¸°ì˜¨ë„ í‰ê· (Â°C)"])
    else:
        ì›”ë³„_í™˜ê¸°ì˜¨ë„ = pd.DataFrame(columns=["ì›”","í™˜ê¸°ì˜¨ë„ í‰ê· (Â°C)"])

    # ğŸŸ© ì›”ë³„ í™˜ê¸°ìŠµë„/ì™¸ê¸°ìŠµë„ í‰ê· 
    if raw is not None and not raw.empty:
        df_rah = raw[raw["í•­ëª©ëª…"] == "RAH"].copy()
        if not df_rah.empty:
            df_rah["ì›”"] = df_rah["datetime"].dt.to_period("M")
            ì›”ë³„_í™˜ê¸°ìŠµë„ = df_rah.groupby("ì›”")["ê°’"].mean().reset_index(name="í™˜ê¸°ìŠµë„ í‰ê· (%)")
        else:
            ì›”ë³„_í™˜ê¸°ìŠµë„ = pd.DataFrame(columns=["ì›”","í™˜ê¸°ìŠµë„ í‰ê· (%)"])
    else:
        ì›”ë³„_í™˜ê¸°ìŠµë„ = pd.DataFrame(columns=["ì›”","í™˜ê¸°ìŠµë„ í‰ê· (%)"])

    # ğŸŸ© ì™¸ê¸° ë°ì´í„° ì²˜ë¦¬
    if not ì™¸ê¸°df_hourly.empty:
        _oa = ì™¸ê¸°df_hourly.copy()
        _oa["ì›”"] = _oa["datetime"].dt.to_period("M")
        ì›”ë³„_ì™¸ê¸°ì˜¨ë„ = _oa.groupby("ì›”")["ì™¸ê¸°ì˜¨ë„"].mean().reset_index(name="ì™¸ê¸°ì˜¨ë„ í‰ê· (Â°C)")
        ì›”ë³„_ì™¸ê¸°ìŠµë„ = _oa.groupby("ì›”")["ì™¸ê¸°ìŠµë„"].mean().reset_index(name="ì™¸ê¸°ìŠµë„ í‰ê· (%)")
    else:
        ì›”ë³„_ì™¸ê¸°ì˜¨ë„ = pd.DataFrame(columns=["ì›”","ì™¸ê¸°ì˜¨ë„ í‰ê· (Â°C)"])
        ì›”ë³„_ì™¸ê¸°ìŠµë„ = pd.DataFrame(columns=["ì›”","ì™¸ê¸°ìŠµë„ í‰ê· (%)"])

    # ğŸŸ© ë³‘í•©: í™˜ê¸° â†” ì™¸ê¸°
    ì›”ë³„_í™˜ê¸°ì˜¨ë„_í‘œ = pd.merge(ì›”ë³„_í™˜ê¸°ì˜¨ë„, ì›”ë³„_ì™¸ê¸°ì˜¨ë„, on="ì›”", how="outer")
    ì›”ë³„_í™˜ê¸°ìŠµë„_í‘œ = pd.merge(ì›”ë³„_í™˜ê¸°ìŠµë„, ì›”ë³„_ì™¸ê¸°ìŠµë„, on="ì›”", how="outer")



    # ğŸŸ© ê°œë³„ í•­ëª© ì‹œê°í™”
    for ì„ íƒí•­ëª© in ["CCV", "PC_CCV", "HCV", "DH_HCV", "RAT", "RAH"]:
        if raw is not None and not raw.empty:
            df_selected = raw[raw["í•­ëª©ëª…"] == ì„ íƒí•­ëª©].copy()
        else:
            df_selected = pd.DataFrame()

        if df_selected.empty:
            continue

        # ğŸ‘‰ ì—¬ê¸°ì„œ ê·¸ë˜í”„ ì²˜ë¦¬ (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)


        if ì„ íƒí•­ëª© in ["CCV", "PC_CCV"]:
            y_col = f"{ì„ íƒí•­ëª©}_kWh"
            í•­ëª©_ì¶œë ¥ëª… = í•­ëª©ëª…_í•œê¸€.get(ì„ íƒí•­ëª©, ì„ íƒí•­ëª©)
            title = f"â„ï¸ ì¼ì¼ ëƒ‰ìˆ˜ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ({í•­ëª©_ì¶œë ¥ëª…})"
            mx = í•­ëª©_ì—´ëŸ‰ë§µí•‘[ì„ íƒí•­ëª©].get(ahu, 0)

            # âœ… ì—´ëŸ‰ ê³„ì‚° ê³µí†µ ì²˜ë¦¬
            df_selected["ì‹œê°„ê°„ê²©"] = df_selected["datetime"].diff().dt.total_seconds().div(3600).fillna(0)
            df_selected = df_selected[(df_selected["ì‹œê°„ê°„ê²©"] > 0) & (df_selected["ì‹œê°„ê°„ê²©"] <= 12)].copy()
            df_selected[y_col] = (
                df_selected["ê°’"].shift(1).add(df_selected["ê°’"]).div(2)
                * mx * df_selected["ì‹œê°„ê°„ê²©"] / 100 / 860
            )
            df_selected["ë‚ ì§œ"] = df_selected["datetime"].dt.date
            ì¼ë³„_ì§‘ê³„ = df_selected.groupby("ë‚ ì§œ")[y_col].sum().reset_index()
            ì¼ë³„_ì§‘ê³„["ê³µì¡°ê¸°"] = ahu

            ì¼ë³„_ì§‘ê³„["ì—°ë„"] = pd.to_datetime(ì¼ë³„_ì§‘ê³„["ë‚ ì§œ"]).dt.year
            ì¼ë³„_ì§‘ê³„["ì ˆê¸°"] = pd.to_datetime(ì¼ë³„_ì§‘ê³„["ë‚ ì§œ"]).apply(ì ˆê¸°_ë¶„ë¥˜)
            ì¼ë³„_ì§‘ê³„["ì›”ì¼"] = pd.to_datetime(ì¼ë³„_ì§‘ê³„["ë‚ ì§œ"]).dt.strftime("%m-%d")
            ìƒ‰ìƒ_ë¦¬ìŠ¤íŠ¸ = px.colors.qualitative.Set1 + px.colors.qualitative.Set2 + px.colors.qualitative.Plotly
            ìƒ‰ìƒ_ìˆœí™˜ê¸° = itertools.cycle(ìƒ‰ìƒ_ë¦¬ìŠ¤íŠ¸)
            ê³ ìœ _ë ˆì „ë“œ = ì¼ë³„_ì§‘ê³„["ê³µì¡°ê¸°"] + " | " + ì¼ë³„_ì§‘ê³„["ì—°ë„"].astype(str)
            color_map = {ë ˆì „ë“œ: next(ìƒ‰ìƒ_ìˆœí™˜ê¸°) for ë ˆì „ë“œ in sorted(ê³ ìœ _ë ˆì „ë“œ.unique())}
            st.subheader(title)

            with st.expander(f"{title}_ì ˆê¸°ë³„ íŠ¸ë Œë“œ", expanded=False):
                draw_season_year_line(
                    ì¼ë³„_ì§‘ê³„,
                    y_col=y_col,
                    title=title,
                    í‰ê· ì„ _ì»¬ëŸ¼=y_col,
                    color_map=color_map
                )
            with st.expander(f"â±ï¸ ê°œë„ìœ¨ íŠ¸ë Œë“œ ({í•­ëª©_ì¶œë ¥ëª…})", expanded=False):
                draw_overlay_by_shifted_datetime(
                    df=df_selected,
                    y_col="ê°’",
                    title=f"â±ï¸ ê°œë„ìœ¨ íŠ¸ë Œë“œ ({í•­ëª©_ì¶œë ¥ëª…})",
                    í‰ê· ì„ _ì»¬ëŸ¼="ê°’"
                )
            

        elif ì„ íƒí•­ëª© in ["HCV", "DH_HCV"]:
            y_col = f"{ì„ íƒí•­ëª©}_kWh"
            í•­ëª©_ì¶œë ¥ëª… = í•­ëª©ëª…_í•œê¸€.get(ì„ íƒí•­ëª©, ì„ íƒí•­ëª©)
            title = f"ğŸ”¥ ì¼ì¼ ì¦ê¸° ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ({í•­ëª©_ì¶œë ¥ëª…})"
            mx = í•­ëª©_ì—´ëŸ‰ë§µí•‘[ì„ íƒí•­ëª©].get(ahu, 0)

            # âœ… ì—´ëŸ‰ ê³„ì‚° ê³µí†µ ì²˜ë¦¬
            df_selected["ì‹œê°„ê°„ê²©"] = df_selected["datetime"].diff().dt.total_seconds().div(3600).fillna(0)
            df_selected = df_selected[(df_selected["ì‹œê°„ê°„ê²©"] > 0) & (df_selected["ì‹œê°„ê°„ê²©"] <= 12)].copy()
            df_selected[y_col] = (
                df_selected["ê°’"].shift(1).add(df_selected["ê°’"]).div(2)
                * mx * df_selected["ì‹œê°„ê°„ê²©"] / 100 / 860
            )
            df_selected["ë‚ ì§œ"] = df_selected["datetime"].dt.date
            ì¼ë³„_ì§‘ê³„ = df_selected.groupby("ë‚ ì§œ")[y_col].sum().reset_index()
            ì¼ë³„_ì§‘ê³„["ê³µì¡°ê¸°"] = ahu

            ì¼ë³„_ì§‘ê³„["ì—°ë„"] = pd.to_datetime(ì¼ë³„_ì§‘ê³„["ë‚ ì§œ"]).dt.year
            ì¼ë³„_ì§‘ê³„["ì ˆê¸°"] = pd.to_datetime(ì¼ë³„_ì§‘ê³„["ë‚ ì§œ"]).apply(ì ˆê¸°_ë¶„ë¥˜)
            ì¼ë³„_ì§‘ê³„["ì›”ì¼"] = pd.to_datetime(ì¼ë³„_ì§‘ê³„["ë‚ ì§œ"]).dt.strftime("%m-%d")
            ìƒ‰ìƒ_ë¦¬ìŠ¤íŠ¸ = px.colors.qualitative.Set1 + px.colors.qualitative.Set2 + px.colors.qualitative.Plotly
            ìƒ‰ìƒ_ìˆœí™˜ê¸° = itertools.cycle(ìƒ‰ìƒ_ë¦¬ìŠ¤íŠ¸)
            ê³ ìœ _ë ˆì „ë“œ = ì¼ë³„_ì§‘ê³„["ê³µì¡°ê¸°"] + " | " + ì¼ë³„_ì§‘ê³„["ì—°ë„"].astype(str)
            color_map = {ë ˆì „ë“œ: next(ìƒ‰ìƒ_ìˆœí™˜ê¸°) for ë ˆì „ë“œ in sorted(ê³ ìœ _ë ˆì „ë“œ.unique())}

            st.subheader(title)

            with st.expander(f"{title}_ì ˆê¸°ë³„ íŠ¸ë Œë“œ", expanded=False):
                draw_season_year_line(
                    ì¼ë³„_ì§‘ê³„,
                    y_col=y_col,
                    title=title + " (ì ˆê¸°ë³„ íŠ¸ë Œë“œ)",
                    í‰ê· ì„ _ì»¬ëŸ¼=y_col,
                    color_map=color_map
                )

            with st.expander(f"â±ï¸ ê°œë„ìœ¨ íŠ¸ë Œë“œ ({í•­ëª©_ì¶œë ¥ëª…})", expanded=False):
                draw_overlay_by_shifted_datetime(
                    df=df_selected,
                    y_col="ê°’",
                    title=f"â±ï¸ ê°œë„ìœ¨ íŠ¸ë Œë“œ ({í•­ëª©_ì¶œë ¥ëª…})",
                    í‰ê· ì„ _ì»¬ëŸ¼="ê°’",
                    color_map=color_map
                )
            
        elif ì„ íƒí•­ëª© in ["RAT", "RAH"]:
            if "í™˜ê¸°_ì™¸ê¸°_ìš”ì•½_ì¶œë ¥ë¨" not in st.session_state:
                st.markdown("### ğŸŒ¡ï¸ğŸ’§ í™˜ê¸°ì˜¨ìŠµë„Â·ì™¸ê¸°ì˜¨ìŠµë„ íŠ¸ë Œë“œ")
                st.session_state["í™˜ê¸°_ì™¸ê¸°_ìš”ì•½_ì¶œë ¥ë¨"] = True

            if not ì™¸ê¸°df_hourly.empty:
                label = "í™˜ê¸°ì˜¨ë„" if ì„ íƒí•­ëª© == "RAT" else "í™˜ê¸°ìŠµë„"
                with st.expander(f"ğŸ“ˆ {label} ë° ì™¸ê¸° ë¹„êµ", expanded=False):
                    

                    for ì—°ë„ in sorted(df_selected["datetime"].dt.year.unique()):
                        df_year  = df_selected[df_selected["datetime"].dt.year == ì—°ë„].copy()
                        ext_year = ì™¸ê¸°df_hourly[ì™¸ê¸°df_hourly["datetime"].dt.year == ì—°ë„].copy()

                        if df_year.empty:
                            continue

                        fig = go.Figure()

                        # âœ… ì™¸ê¸°ê°’ ì²˜ë¦¬
                        ext_year = ext_year.sort_values("datetime")
                        ext_year["ì‹œê°„ì°¨"] = ext_year["datetime"].diff().dt.total_seconds().div(60)
                        ext_year["gap_group"] = (ext_year["ì‹œê°„ì°¨"] > 300).cumsum()

                        ext_legend_shown = False
                        if ì„ íƒí•­ëª© == "RAT":
                            for _, g in ext_year.groupby("gap_group"):
                                if g.empty: 
                                    continue
                                fig.add_trace(go.Scatter(
                                    x=g["datetime"], y=g["ì™¸ê¸°ì˜¨ë„"],
                                    mode="lines", name="ì™¸ê¸°ì˜¨ë„",
                                    line=dict(color="gray"),
                                    connectgaps=False,
                                    showlegend=not ext_legend_shown,  # â† ì²« ê·¸ë£¹ë§Œ ë²”ë¡€ í‘œì‹œ
                                    legendgroup="ì™¸ê¸°ì˜¨ë„"
                                ))
                                ext_legend_shown = True
                        else:
                            for _, g in ext_year.groupby("gap_group"):
                                if g.empty:
                                    continue
                                fig.add_trace(go.Scatter(
                                    x=g["datetime"], y=g["ì™¸ê¸°ìŠµë„"],
                                    mode="lines", name="ì™¸ê¸°ìŠµë„",
                                    line=dict(color="gray"),
                                    connectgaps=False,
                                    showlegend=not ext_legend_shown,  # â† ì²« ê·¸ë£¹ë§Œ ë²”ë¡€ í‘œì‹œ
                                    legendgroup="ì™¸ê¸°ìŠµë„"
                                ))
                                ext_legend_shown = True

                        # âœ… í™˜ê¸°ê°’ ì²˜ë¦¬
                        df_year = df_year.sort_values("datetime")
                        df_year["ì‹œê°„ì°¨"] = df_year["datetime"].diff().dt.total_seconds().div(60)
                        df_year["gap_group"] = (df_year["ì‹œê°„ì°¨"] > 300).cumsum()

                        vent_name = "í™˜ê¸°ì˜¨ë„" if ì„ íƒí•­ëª© == "RAT" else "í™˜ê¸°ìŠµë„"
                        vent_legend_shown = False  # â† ì¶”ê°€
                        for _, g in df_year.groupby("gap_group"):
                            if g.empty:
                                continue
                            fig.add_trace(go.Scatter(
                                x=g["datetime"], y=g["ê°’"],
                                mode="lines", name=vent_name,
                                line=dict(color="blue"),
                                connectgaps=False,
                                showlegend=not vent_legend_shown,  # â† ì²« ê·¸ë£¹ë§Œ ë²”ë¡€ í‘œì‹œ
                                legendgroup="í™˜ê¸°"
                            ))
                            vent_legend_shown = True


                        # âœ… ê¸°ì¤€ì„  ë° ë°´ë“œ
                        if ì„ íƒí•­ëª© == "RAT":
                            if ahu in BAND_RANGES_RAT:
                                for ymin, ymax in BAND_RANGES_RAT[ahu]:
                                    fig = add_band(fig, ymin, ymax, color="orange", label="ê²½ê³ êµ¬ê°„")
                            if ahu in AHU_RAT_LIMITS:
                                fig.add_hline(y=AHU_RAT_LIMITS[ahu][0], line_dash="dot", line_color="red",
                                                annotation_text=f"{AHU_RAT_LIMITS[ahu][0]}Â°C", annotation_position="top left")
                                fig.add_hline(y=AHU_RAT_LIMITS[ahu][1], line_dash="dot", line_color="red",
                                                annotation_text=f"{AHU_RAT_LIMITS[ahu][1]}Â°C", annotation_position="top left")
                            fig.update_layout(
                                title=f"{ì—°ë„}ë…„ í™˜ê¸°ì˜¨ë„ ë° ì™¸ê¸°ì˜¨ë„",
                                xaxis_title="ë‚ ì§œ", yaxis_title="ì˜¨ë„", legend=dict(y=1, x=1.05)
                            )
                        else:
                            if ahu in BAND_RANGES_RAH:
                                for ymin, ymax in BAND_RANGES_RAH[ahu]:
                                    fig = add_band(fig, ymin, ymax, color="orange", label="ê²½ê³ êµ¬ê°„")
                            if ahu in AHU_RAH_LIMITS:
                                y_limit = AHU_RAH_LIMITS[ahu][0]
                                fig.add_hline(y=y_limit, line_dash="dot", line_color="red",
                                                annotation_text=f"{y_limit}%", annotation_position="top left")
                            fig.update_layout(
                                title=f"{ì—°ë„}ë…„ í™˜ê¸°ìŠµë„ ë° ì™¸ê¸°ìŠµë„",
                                xaxis_title="ë‚ ì§œ", yaxis_title="ìŠµë„", legend=dict(y=1, x=1.05)
                            )

                        # âœ… ê¸°ë³¸ ì„¤ì •
                        fig.update_xaxes(type="date", showgrid=True, tickformat="%m-%d\n%H:%M")
                        fig.update_yaxes(showline=True, linecolor="black")
                        st.plotly_chart(fig, use_container_width=True)


t_total_end = time.time()
if st.session_state.get("t_total_start") is not None:
    st.success(f"ğŸ§® ì´ ë¶„ì„ ì™„ë£Œ ì‹œê°„: {t_total_end - st.session_state['t_total_start']:.1f}ì´ˆ")

else:
    st.info("ë°ì´í„°ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì ì‹œ í›„ 'ë°ì´í„° ê°•ì œ ì¬ë¶„ì„' ë²„íŠ¼ì„ í´ë¦­í•˜ê±°ë‚˜, history í´ë”ì˜ CSV íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
